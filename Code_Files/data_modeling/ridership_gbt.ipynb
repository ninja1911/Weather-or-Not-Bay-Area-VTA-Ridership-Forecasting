{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    make_scorer,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"clean_data/train.csv\")\n",
    "test_df = pd.read_csv(\"clean_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[[x for x in train_df.columns if x not in [\"On\", \"Off\"]]]\n",
    "Y_train = train_df[\"On\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[[x for x in test_df.columns if x not in [\"On\", \"Off\"]]]\n",
    "Y_test = test_df[\"On\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state = 42, verbose=2)\n",
    "gbr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_gbr = np.floor(gbr.predict(X_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_gbr = float(format(np.sqrt(mean_squared_error(Y_test, Y_pred_gbr)), '.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_FOLDER = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gbr, open(os.path.join(MODELS_FOLDER, \"base_gbt.pkl\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(Y_test, Y_pred_gbr)\n",
    "rmse = root_mean_squared_error(Y_test, Y_pred_gbr)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_gbr)\n",
    "print(f\"test rmse: {rmse}, mae: {mae}, r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_gbr = np.floor(gbr.predict(X_train)).astype(int)\n",
    "r2 = r2_score(Y_train, Y_pred_gbr)\n",
    "rmse = root_mean_squared_error(Y_train, Y_pred_gbr)\n",
    "mae = mean_absolute_error(Y_train, Y_pred_gbr)\n",
    "print(f\"train rmse: {rmse}, mae: {mae}, r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gbt = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    loss=\"squared_error\",\n",
    "    criterion=\"friedman_mse\",\n",
    "    min_samples_split=14,\n",
    "    min_samples_leaf=7,\n",
    "    verbose=2,\n",
    ")\n",
    "param_grid = [\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [50],\n",
    "        \"max_depth\": [20],\n",
    "        \"max_features\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [50],\n",
    "        \"max_depth\": [100],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [10],\n",
    "        \"max_depth\": [70],\n",
    "        \"max_features\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [10],\n",
    "        \"max_depth\": [100],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = GridSearchCV(base_gbt, param_grid, scoring=scorer, n_jobs=-1, verbose=2, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        2087.1713         355.3899           17.93m\n",
      "         1        2079.8868         343.0553           17.93m\n",
      "         1        2467.7258           3.7548           18.01m\n",
      "         1        2455.4581           3.6229           18.10m\n",
      "         1        2446.0411           3.6425           18.28m\n",
      "         1        2069.7851         345.0086           18.37m\n",
      "         1        2069.0214           22.30m\n",
      "         1        2478.1808           22.41m\n",
      "         1        2455.3136           22.45m\n",
      "         1        2444.3305           22.87m\n",
      "         2        1780.7542         331.7645           17.79m\n",
      "         2        1789.0708         347.8011           17.84m\n",
      "         2        2459.7113          36.6690           17.89m\n",
      "         2        2474.8930          48.4880           17.95m\n",
      "         2        2452.6621          46.1634           18.02m\n",
      "         2        1774.2512         343.8445           18.19m\n",
      "         2        2451.3242           21.87m\n",
      "         2        1760.1033           21.97m\n",
      "         2        2474.1500           22.07m\n",
      "         2        2440.3478           22.28m\n",
      "         3        1534.2270         242.4346           17.45m\n",
      "         3        1536.5478         269.5264           17.46m\n",
      "         3        2457.9393          12.4894           17.57m\n",
      "         3        2467.2908         -10.5741           17.58m\n",
      "         3        2455.0798          29.3068           17.67m\n",
      "         3        1526.7810         257.4743           17.86m\n",
      "         3        1508.5974           21.69m\n",
      "         3        2447.3425           21.69m\n",
      "         3        2470.1271           21.84m\n",
      "         3        2436.3731           21.92m\n",
      "         4        1324.1749         195.0185           17.26m\n",
      "         4        1314.6113         136.3170           17.34m\n",
      "         4        2428.7572         -97.0950           17.36m\n",
      "         4        2453.1440         -36.7375           17.43m\n",
      "         4        2431.3594         -75.3131           17.46m\n",
      "         4        1312.0284         162.1095           17.60m\n",
      "         4        2443.3660           21.39m\n",
      "         4        1303.4271           21.41m\n",
      "         4        2432.4064           21.53m\n",
      "         4        2466.1123           21.55m\n",
      "         5        1166.1255         216.6206           17.01m\n",
      "         5        1148.3430         175.5244           17.08m\n",
      "         5        2428.7932          19.7458           17.18m\n",
      "         5        2474.1575         103.8732           17.24m\n",
      "         5        2423.2003         -13.0807           17.26m\n",
      "         5        1141.7858         152.6649           17.36m\n",
      "         6        1022.8437         118.3328           16.70m\n",
      "         6        1021.5974         180.9065           16.74m\n",
      "         6        2442.5664          74.5607           16.82m\n",
      "         6        2437.9640          78.5999           16.86m\n",
      "         6        2458.7438         -41.9891           16.91m\n",
      "         6        1013.0101         173.9401           16.97m\n",
      "         5        2439.3973           20.97m\n",
      "         5        1135.7069           21.08m\n",
      "         5        2428.4477           21.15m\n",
      "         5        2462.1054           21.26m\n",
      "         7         909.1432         118.7596           16.38m\n",
      "         7         898.2587          69.0209           16.43m\n",
      "         7        2413.5814         -96.5640           16.45m\n",
      "         7        2415.2872         -71.2795           16.49m\n",
      "         7        2453.2841          -2.0606           16.53m\n",
      "         7         894.9534          91.2448           16.58m\n",
      "         6        2435.4371           20.56m\n",
      "         6         997.7612           20.65m\n",
      "         6        2424.4969           20.68m\n",
      "         6        2458.1026           20.80m\n",
      "         8         808.8670          69.2054           15.98m\n",
      "         8         812.2637         129.6840           16.02m\n",
      "         8        2433.4088          98.8406           16.03m\n",
      "         8        2425.1984          59.0770           16.07m\n",
      "         8        2443.0015         -21.5362           16.08m\n",
      "         8         802.6833         101.3567           16.15m\n",
      "         7        2431.4842           20.11m\n",
      "         7         884.4158           20.12m\n",
      "         7        2420.5537           20.20m\n",
      "         7        2454.1074           20.29m\n",
      "         9         740.8382         120.8606           15.58m\n",
      "         9         730.6369          63.2313           15.61m\n",
      "         9        2418.5239          -7.3403           15.62m\n",
      "         9        2423.9970         -18.2450           15.62m\n",
      "         9        2464.7267         106.5381           15.67m\n",
      "         9         724.5014          74.7507           15.70m\n",
      "         8         790.1528           19.59m\n",
      "         8        2427.5395           19.61m\n",
      "         8        2416.6189           19.69m\n",
      "         8        2450.1199           19.80m\n",
      "        10         673.0483          53.9725           15.16m\n",
      "        10        2394.2057         -78.0077           15.22m\n",
      "        10         660.1621          40.4413           15.21m\n",
      "        10        2409.4736         -38.7723           15.22m\n",
      "        10        2444.0706         -63.0046           15.23m\n",
      "        10         650.8903          22.0392           15.26m\n",
      "        11         617.7645          47.8567           14.86m\n",
      "        11         613.4808          82.3734           14.88m\n",
      "        11        2412.1836          91.2553           14.89m\n",
      "        11        2439.0091          -0.6856           14.90m\n",
      "        11        2415.2980          42.6734           14.90m\n",
      "         9         712.0880           19.16m\n",
      "        11         608.4218          97.7839           14.91m\n",
      "         9        2423.6026           19.19m\n",
      "         9        2412.6916           19.22m\n",
      "         9        2446.1407           19.38m\n",
      "        12         579.0307          74.5227           14.45m\n",
      "        12         565.5034          31.7339           14.45m\n",
      "        12         560.2448          28.7072           14.48m\n",
      "        12        2384.8287         -90.1710           14.49m\n",
      "        12        2396.0108         -57.8941           14.49m\n",
      "        12        2445.3316          44.9318           14.49m\n",
      "        10         647.3384           18.64m\n",
      "        10        2419.6733           18.69m\n",
      "        10        2408.7704           18.73m\n",
      "        10        2442.1687           18.86m\n",
      "        13         531.8445           4.4452           14.04m\n",
      "        13         534.4877          69.2355           14.05m\n",
      "        13         527.7741          61.1443           14.08m\n",
      "        13        2407.5287         110.0441           14.09m\n",
      "        13        2422.1566         -73.3007           14.10m\n",
      "        13        2415.2382          96.2386           14.10m\n",
      "        11         594.1429           18.21m\n",
      "        11        2415.7505           18.32m\n",
      "        11        2404.8559           18.34m\n",
      "        11        2438.2055           18.47m\n",
      "        14         501.8628          40.2406           13.77m\n",
      "        14         496.2390           7.1220           13.78m\n",
      "        14         490.1498           8.3567           13.80m\n",
      "        14        2381.8247         -83.6239           13.82m\n",
      "        14        2424.1588          27.2907           13.83m\n",
      "        14        2387.4183         -92.1200           13.85m\n",
      "        12         549.4734           17.91m\n",
      "        12        2411.8370           17.97m\n",
      "        12        2400.9523           17.98m\n",
      "        12        2434.2500           18.11m\n",
      "        15         475.6896          58.2215           13.45m\n",
      "        15         477.2020          41.1187           13.46m\n",
      "        15         470.3316          60.7881           13.47m\n",
      "        15        2436.8234          70.1721           13.51m\n",
      "        15        2407.2025         120.7584           13.52m\n",
      "        15        2412.6817         120.3030           13.54m\n",
      "        13         511.6580           17.52m\n",
      "        16         447.5041           1.2105           13.13m\n",
      "        13        2407.9309           17.60m\n",
      "        13        2397.0533           17.61m\n",
      "        16         444.9224          -2.2505           13.16m\n",
      "        16         443.0519           9.0821           13.17m\n",
      "        16        2414.8661         -68.5552           13.20m\n",
      "        16        2394.3762         -32.1462           13.21m\n",
      "        16        2400.3857         -30.0155           13.24m\n",
      "        13        2430.3024           17.76m\n",
      "        17         427.3505          22.2935           12.86m\n",
      "        17         422.9510          20.9663           12.89m\n",
      "        17        2429.1685          76.5743           12.89m\n",
      "        17         430.3133          47.8439           12.89m\n",
      "        17        2388.3771          -4.8688           12.91m\n",
      "        14         479.7322           17.20m\n",
      "        17        2405.5494          39.8528           12.99m\n",
      "        14        2393.1622           17.27m\n",
      "        14        2404.0320           17.31m\n",
      "        14        2426.3627           17.46m\n",
      "        18         416.1142          49.0870           12.56m\n",
      "        18         409.8863          35.9610           12.59m\n",
      "        18        2415.1560         -36.8939           12.59m\n",
      "        18         412.0240          13.6128           12.59m\n",
      "        18        2396.2529          50.5718           12.61m\n",
      "        18        2401.3554           2.3479           12.67m\n",
      "        15         453.0669           16.87m\n",
      "        15        2389.2791           16.95m\n",
      "        15        2400.1411           16.97m\n",
      "        15        2422.4310           17.14m\n",
      "        19         395.3214          -5.2450           12.25m\n",
      "        19         390.6379           1.5141           12.26m\n",
      "        19         399.2130          25.2846           12.26m\n",
      "        19        2390.8102          -2.7156           12.26m\n",
      "        19        2415.0987          19.0480           12.28m\n",
      "        19        2391.5297         -20.2791           12.35m\n",
      "        16         429.9370           16.46m\n",
      "        16        2385.4057           16.53m\n",
      "        16        2396.2582           16.57m\n",
      "        16        2418.5072           16.69m\n",
      "        20         373.1148          -5.8472           11.88m\n",
      "        20         378.2716         -18.7151           11.88m\n",
      "        20        2353.6938        -129.5179           11.88m\n",
      "        20         377.8528          -1.2438           11.89m\n",
      "        20        2385.3253         -99.8453           11.91m\n",
      "        20        2385.6084          -4.6046           11.97m\n",
      "        17         409.8889           15.94m\n",
      "        17        2381.5385           16.00m\n",
      "        17        2392.3820           16.04m\n",
      "        21         360.8018          11.1276           11.45m\n",
      "        21        2361.2833          49.2574           11.45m\n",
      "        21         367.2865          15.4041           11.46m\n",
      "        21         372.3253          46.2269           11.47m\n",
      "        17        2414.5913           16.14m\n",
      "        21        2408.3762         111.4844           11.49m\n",
      "        21        2378.4808          -9.6139           11.55m\n",
      "        22         349.8406          11.2017           11.04m\n",
      "        22         353.2797           2.5830           11.05m\n",
      "        18         392.5349           15.44m\n",
      "        22        2359.1440          10.2905           11.06m\n",
      "        22         358.6101           2.8066           11.06m\n",
      "        22        2413.7075          40.5714           11.08m\n",
      "        18        2377.6794           15.48m\n",
      "        18        2388.5148           15.52m\n",
      "        22        2361.9091         -47.4031           11.13m\n",
      "        18        2410.6841           15.61m\n",
      "        23         345.1573          28.5224           10.64m\n",
      "        23         351.0585          38.1633           10.65m\n",
      "        23        2370.5899          64.7791           10.66m\n",
      "        23         346.3761           2.7479           10.67m\n",
      "        23        2390.6865         -72.9666           10.69m\n",
      "        23        2375.9444          75.0923           10.74m\n",
      "        19         377.7027           14.96m\n",
      "        19        2373.8278           15.02m\n",
      "        19        2384.6541           15.04m\n",
      "        19        2406.7843           15.14m\n",
      "        24         336.5629          12.1427           10.28m\n",
      "        24        2361.9862         -15.5469           10.29m\n",
      "        24         342.3950          10.8772           10.29m\n",
      "        24         338.5506          13.1820           10.30m\n",
      "        24        2398.2266          49.2631           10.33m\n",
      "        24        2377.7928          26.1695           10.37m\n",
      "        20         364.6504           14.52m\n",
      "        20        2369.9839           14.54m\n",
      "        20        2380.8017           14.57m\n",
      "        20        2402.8918           14.65m\n",
      "        25        2331.3227        -103.9315            9.88m\n",
      "        25         320.9847         -19.9080            9.89m\n",
      "        25         330.7555          14.2480            9.90m\n",
      "        25         329.6772          -8.5958            9.90m\n",
      "        25        2403.9943          42.1199            9.93m\n",
      "        25        2357.2762         -63.3215            9.96m\n",
      "        21         352.8724           14.02m\n",
      "        21        2366.1494           14.03m\n",
      "        21        2376.9577           14.05m\n",
      "        21        2399.0078           14.16m\n",
      "        26        2340.5514          55.6413            9.49m\n",
      "        26         324.6561          10.3069            9.51m\n",
      "        26         317.2869          24.4226            9.51m\n",
      "        26         321.8242          13.0822            9.53m\n",
      "        26        2378.2629         -83.9089            9.54m\n",
      "        26        2361.3481          35.1128            9.60m\n",
      "        22         342.9301           13.60m\n",
      "        22        2362.3205           13.60m\n",
      "        22        2373.1200           13.62m\n",
      "        27        2345.7523          39.5659            9.12m\n",
      "        27         312.4236         -14.0614            9.15m\n",
      "        27         309.6039           1.3877            9.16m\n",
      "        27        2362.1499         -45.5617            9.17m\n",
      "        22        2395.1312           13.71m\n",
      "        27         312.1691          -0.2893            9.17m\n",
      "        27        2348.9501         -30.9230            9.21m\n",
      "        28        2361.6006          82.1073            8.75m\n",
      "        28         308.7764          12.1354            8.79m\n",
      "        28        2382.2741          99.4379            8.80m\n",
      "        28         307.1586          33.2525            8.80m\n",
      "        23        2358.4997           13.17m\n",
      "        28         306.4065          18.0063            8.82m\n",
      "        23        2369.2897           13.18m\n",
      "        23         333.4464           13.18m\n",
      "        28        2354.1515          39.5194            8.84m\n",
      "        23        2391.2620           13.27m\n",
      "        29        2327.4720        -117.9200            8.37m\n",
      "        29        2356.6450         -83.7359            8.40m\n",
      "        29         301.0958           0.5919            8.41m\n",
      "        29         296.2769         -15.1111            8.42m\n",
      "        29         301.9623          13.4717            8.43m\n",
      "        29        2343.3742         -24.4340            8.44m\n",
      "        24        2354.6854           12.69m\n",
      "        24        2365.4680           12.70m\n",
      "        24         325.5558           12.71m\n",
      "        24        2387.4007           12.76m\n",
      "        30        2341.4558          74.4124            7.95m\n",
      "        30        2366.4157          57.9448            7.99m\n",
      "        30         296.9728          14.2465            8.00m\n",
      "        30         293.7182          21.7113            8.00m\n",
      "        30         296.8689           9.0162            8.01m\n",
      "        30        2353.1177          57.6076            8.02m\n",
      "        25        2350.8824           12.15m\n",
      "        25        2361.6533           12.16m\n",
      "        25         318.0880           12.19m\n",
      "        25        2383.5468           12.22m\n",
      "        31        2345.9683          36.6789            7.53m\n",
      "        31        2358.5498         -12.6686            7.57m\n",
      "        31         290.2273          13.3327            7.59m\n",
      "        31         291.9258          11.1672            7.59m\n",
      "        31        2344.2345         -16.9224            7.60m\n",
      "        31         289.6398          -1.9093            7.60m\n",
      "        26        2347.0829           11.64m\n",
      "        26        2357.8467           11.65m\n",
      "        26         311.2283           11.68m\n",
      "        32        2330.4089         -43.7022            7.12m\n",
      "        26        2379.7011           11.71m\n",
      "        32        2359.1890          21.2734            7.16m\n",
      "        32         282.0342          -7.5216            7.18m\n",
      "        32         284.5032          -3.9118            7.19m\n",
      "        32        2339.7535           0.6349            7.19m\n",
      "        32         285.2905           5.6329            7.19m\n",
      "        33        2329.4751          14.7683            6.73m\n",
      "        27        2343.2920           11.15m\n",
      "        27        2354.0479           11.17m\n",
      "        33        2370.9681          65.8617            6.77m\n",
      "        27         305.0657           11.21m\n",
      "        33        2336.2390           4.4944            6.79m\n",
      "        33         276.7897           2.7861            6.79m\n",
      "        33         281.6737          13.4880            6.79m\n",
      "        27        2375.8628           11.24m\n",
      "        33         279.3778           0.0699            6.81m\n",
      "        34        2312.8009         -48.3112            6.32m\n",
      "        34        2346.6623         -78.5934            6.36m\n",
      "        28        2339.5095           10.63m\n",
      "        34         278.5582           9.9926            6.38m\n",
      "        34        2317.5912         -56.1366            6.38m\n",
      "        34         270.6561           1.0350            6.38m\n",
      "        28        2350.2557           10.65m\n",
      "        34         273.1513           2.7365            6.39m\n",
      "        28         299.2527           10.70m\n",
      "        28        2372.0323           10.71m\n",
      "        35        2320.6025          49.6241            5.91m\n",
      "        35        2367.1261         100.5143            5.94m\n",
      "        35        2316.6002          14.5115            5.97m\n",
      "        35         273.6173           6.1045            5.97m\n",
      "        35         267.0739           3.8545            5.98m\n",
      "        35         266.6085           3.2443            5.98m\n",
      "        29        2335.7324           10.12m\n",
      "        29        2346.4725           10.14m\n",
      "        29        2368.2094           10.20m\n",
      "        29         293.4229           10.20m\n",
      "        36        2301.3985         -58.4057            5.51m\n",
      "        36        2340.3929         -88.2435            5.53m\n",
      "        36        2319.9730          31.9297            5.56m\n",
      "        36         266.9796          -0.0916            5.57m\n",
      "        36         261.3007           5.4284            5.58m\n",
      "        36         261.6963           5.2778            5.58m\n",
      "        30        2331.9655            9.61m\n",
      "        30        2342.6955            9.63m\n",
      "        30        2364.3937            9.69m\n",
      "        37        2292.9369         -15.5688            5.11m\n",
      "        30         286.9364            9.70m\n",
      "        37        2344.9863          36.9456            5.13m\n",
      "        37        2315.5265           0.6295            5.15m\n",
      "        37         262.8921           5.7492            5.17m\n",
      "        37         257.2004           5.8718            5.17m\n",
      "        37         257.8800          13.9715            5.18m\n",
      "        31        2328.2048            9.13m\n",
      "        31        2338.9258            9.15m\n",
      "        38        2305.8747          70.1279            4.72m\n",
      "        38        2351.2300          43.5431            4.74m\n",
      "        31        2360.5852            9.21m\n",
      "        31         282.1804            9.23m\n",
      "        38        2327.4458          66.0429            4.76m\n",
      "        38         254.2535          14.0227            4.79m\n",
      "        38         259.5738          13.1226            4.80m\n",
      "        38         255.6819          11.4630            4.80m\n",
      "        39        2301.0333          -1.0894            4.33m\n",
      "        32        2324.4515            8.67m\n",
      "        39        2335.7358         -43.3948            4.35m\n",
      "        32        2335.1656            8.68m\n",
      "        39        2310.0622         -51.2621            4.37m\n",
      "        32        2356.7850            8.73m\n",
      "        32         277.0163            8.77m\n",
      "        39         248.4630          -0.8258            4.40m\n",
      "        39         253.0298          -0.4714            4.41m\n",
      "        39         249.7459          -0.9428            4.41m\n",
      "        40        2273.2244         -92.9846            3.94m\n",
      "        40        2320.6377         -41.9472            3.96m\n",
      "        40        2305.5966           0.5151            3.97m\n",
      "        33        2320.7042            8.19m\n",
      "        33        2331.4111            8.20m\n",
      "        40         240.2774         -13.0326            4.01m\n",
      "        33        2352.9919            8.25m\n",
      "        40         246.1876          -9.2594            4.01m\n",
      "        40         242.8689          -3.6504            4.02m\n",
      "        33         272.5892            8.29m\n",
      "        41        2285.0771          65.6016            3.54m\n",
      "        41        2318.5289          10.0968            3.56m\n",
      "        41        2298.5495          -9.9616            3.58m\n",
      "        34        2316.9663            7.70m\n",
      "        34        2327.6651            7.71m\n",
      "        41         237.1752           4.6216            3.61m\n",
      "        41         242.5985           5.9112            3.62m\n",
      "        41         239.5512           8.1835            3.62m\n",
      "        34        2349.2068            7.78m\n",
      "        42        2281.9744           5.7682            3.15m\n",
      "        34         268.3094            7.83m\n",
      "        42        2325.0301          44.4745            3.17m\n",
      "        42        2292.0928          -7.6284            3.19m\n",
      "        35        2313.2334            7.24m\n",
      "        35        2323.9256            7.25m\n",
      "        42         240.7576          17.9881            3.22m\n",
      "        42         235.3258           9.6669            3.22m\n",
      "        42         233.1206          -0.2208            3.23m\n",
      "        43        2297.3234          79.5759            2.76m\n",
      "        35        2345.4290            7.31m\n",
      "        43        2304.7941         -62.5329            2.78m\n",
      "        43        2311.1558          94.4903            2.79m\n",
      "        35         264.3966            7.36m\n",
      "        43         234.4450          -8.4261            2.83m\n",
      "        43         233.3587          13.5853            2.83m\n",
      "        44        2273.0166         -79.0812            2.37m\n",
      "        36        2309.5099            6.76m\n",
      "        43         233.4732          18.8420            2.83m\n",
      "        36        2320.1936            6.77m\n",
      "        44        2312.0184          47.2263            2.38m\n",
      "        36        2341.6572            6.82m\n",
      "        44        2292.3182         -57.1930            2.39m\n",
      "        36         260.5140            6.88m\n",
      "        45        2284.3165          63.2390            1.98m\n",
      "        44         230.7868           0.5917            2.43m\n",
      "        44         230.6545           6.0971            2.43m\n",
      "        44         225.3745          -6.3244            2.43m\n",
      "        37        2305.7924            6.28m\n",
      "        45        2306.5556          -3.6397            1.99m\n",
      "        37        2316.4693            6.29m\n",
      "        45        2277.4102         -41.6481            2.00m\n",
      "        37        2337.8934            6.34m\n",
      "        46        2272.7514         -28.1643            1.58m\n",
      "        37         257.2887            6.40m\n",
      "        45         227.0854           8.6613            2.03m\n",
      "        45         226.3923           2.1363            2.03m\n",
      "        46        2303.3069           5.2559            1.59m\n",
      "        45         222.3740           7.6216            2.03m\n",
      "        38        2302.0838            5.80m\n",
      "        46        2306.1784         133.1708            1.60m\n",
      "        38        2312.7520            5.81m\n",
      "        38        2334.1380            5.85m\n",
      "        47        2260.1277         -32.5662            1.19m\n",
      "        46         223.4061          11.3750            1.62m\n",
      "        46         219.7832         -15.3793            1.62m\n",
      "        47        2295.2461         -14.0418            1.19m\n",
      "        46         220.6384          11.0946            1.63m\n",
      "        38         253.9511            5.90m\n",
      "        47        2283.0238         -74.5787            1.20m\n",
      "        39        2298.3800            5.31m\n",
      "        39        2309.0424            5.32m\n",
      "        48        2273.0999          69.8575           47.43s\n",
      "        39        2330.3888            5.36m\n",
      "        48        2298.3649          30.5836           47.67s\n",
      "        47         218.9855          -3.0048            1.22m\n",
      "        47         215.9690           4.4195            1.22m\n",
      "        47         213.0311          -9.4254            1.22m\n",
      "        48        2278.4825          -0.2362           47.91s\n",
      "        39         249.7046            5.42m\n",
      "        40        2294.6849            4.83m\n",
      "        40        2305.3415            4.84m\n",
      "        49        2272.4126          15.1743           23.70s\n",
      "        49        2307.3126          53.9287           23.83s\n",
      "        40        2326.6480            4.87m\n",
      "        48         218.7291          14.0590           48.75s\n",
      "        48         216.7070          19.3573           48.78s\n",
      "        48         210.3340          11.9780           48.88s\n",
      "        49        2286.2226          49.0147           23.95s\n",
      "        40         246.2556            4.93m\n",
      "        50        2255.8842         -48.2600            0.00s\n",
      "        41        2290.9951            4.34m\n",
      "        41        2301.6454            4.35m\n",
      "        50        2306.8365          16.3287            0.00s\n",
      "        49         215.3392           8.3696           24.38s\n",
      "        49         211.3095           3.1483           24.39s\n",
      "        50        2270.4379         -45.2360            0.00s\n",
      "        41        2322.9139            4.37m\n",
      "        49         207.3005           4.2898           24.43s\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=20.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        41         242.5078            4.43m\n",
      "        42        2287.3134            3.85m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=20.3min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        42        2297.9579            3.86m\n",
      "        50         210.1775          -0.4225            0.00s\n",
      "        50         205.3592          -3.7026            0.00s\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=20.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        50         203.0972          -1.2919            0.00s\n",
      "        42        2319.1867            3.88m\n",
      "         1        2446.1760           3.5610            9.99m\n",
      "         1        2079.3713           21.34m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=20.6min\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=20.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        43        2283.6410            3.36m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=20.7min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        42         235.7778            3.94m\n",
      "        43        2294.2782            3.37m\n",
      "         1        2098.3367           22.11m\n",
      "         2        2452.9246          46.0293            9.76m\n",
      "        43        2315.4670            3.39m\n",
      "         1        2455.5599           3.5550            9.40m\n",
      "         1        2467.8921           3.6527            9.41m\n",
      "         1        2444.4148           11.68m\n",
      "         3        2455.4530          29.1841            9.68m\n",
      "         2        2459.9070          36.5588            9.22m\n",
      "         2        2475.2228          48.3068            9.40m\n",
      "         2        1770.5066           21.06m\n",
      "        44        2279.9734            2.88m\n",
      "        44        2290.6051            2.88m\n",
      "         2        1785.7419           21.63m\n",
      "         4        2431.9064         -75.4094            9.25m\n",
      "         2        2440.5421           11.39m\n",
      "        43         232.1630            3.44m\n",
      "         3        2458.3028          12.3200            9.00m\n",
      "         3        2467.7947         -10.6178            9.06m\n",
      "        44        2311.7545            2.90m\n",
      "         5        2423.8540         -13.3643            9.23m\n",
      "         4        2429.2341         -97.2984            8.98m\n",
      "         3        2436.6861           11.51m\n",
      "         4        2453.7824         -37.0100            9.20m\n",
      "         3        1518.5363           20.96m\n",
      "        45        2276.3147            2.39m\n",
      "         6        2438.8017          78.6175            9.13m\n",
      "        45        2286.9397            2.40m\n",
      "         5        2429.4341          19.6846            9.03m\n",
      "         3        1530.2841           21.67m\n",
      "         5        2474.9147         103.7698            9.09m\n",
      "        44         228.1358            2.95m\n",
      "         4        2432.8538           11.26m\n",
      "        45        2308.0501            2.41m\n",
      "         7        2416.2130         -71.6010            8.86m\n",
      "         6        2443.3418          74.4001            8.85m\n",
      "         6        2459.6434         -42.2070            8.91m\n",
      "         5        2429.0362           10.95m\n",
      "         4        1312.2682           20.53m\n",
      "         8        2426.3003          59.1665            8.59m\n",
      "        46        2272.6609            1.91m\n",
      "         7        2414.4508         -96.8138            8.71m\n",
      "         7        2454.4281          -2.0937            8.72m\n",
      "        46        2283.2819            1.92m\n",
      "         4        1321.5334           21.15m\n",
      "        45         224.8444            2.46m\n",
      "         6        2425.2232           10.71m\n",
      "        46        2304.3524            1.93m\n",
      "         9        2419.7688          -7.5125            8.39m\n",
      "         8        2434.4842          98.8868            8.53m\n",
      "         8        2444.1870         -21.7983            8.57m\n",
      "        10        2395.5178         -78.3816            8.31m\n",
      "         7        2421.3893           10.74m\n",
      "         5        1143.1523           20.45m\n",
      "         9        2425.1700         -18.4590            8.45m\n",
      "         9        2466.0805         106.6654            8.46m\n",
      "        47        2269.0169            1.44m\n",
      "        47        2279.6312            1.44m\n",
      "         5        1150.6297           21.22m\n",
      "        11        2413.6732          91.3942            8.14m\n",
      "        47        2300.6621            1.45m\n",
      "        46         221.1148            1.97m\n",
      "        10        2445.5242         -63.1684            8.26m\n",
      "        10        2410.7814         -38.8520            8.29m\n",
      "         8        2417.5931           10.59m\n",
      "        12        2386.3666         -90.7383            7.91m\n",
      "        11        2440.5846          -0.8934            8.03m\n",
      "        11        2416.7105          42.3473            8.05m\n",
      "         6        1004.7495           20.08m\n",
      "         9        2413.7603           10.32m\n",
      "        48        2265.3802           57.35s\n",
      "        48        2275.9870           57.53s\n",
      "        13        2409.2995         110.4588            7.71m\n",
      "         6        1010.0071           20.70m\n",
      "        12        2397.5576         -57.9303            7.84m\n",
      "        12        2447.0544          44.9114            7.82m\n",
      "        48        2296.9795           57.79s\n",
      "        47         218.5612            1.48m\n",
      "        10        2409.9542           10.12m\n",
      "        14        2383.6883         -83.9956            7.51m\n",
      "        13        2417.0135          96.3936            7.61m\n",
      "        13        2423.9298         -73.6608            7.62m\n",
      "         7         890.2327           19.70m\n",
      "        49        2261.7500           28.66s\n",
      "        11        2406.1580            9.88m\n",
      "        49        2272.3517           28.75s\n",
      "        15        2409.2877         121.0276            7.33m\n",
      "        14        2426.0865          27.3195            7.42m\n",
      "        14        2389.2600         -92.6976            7.46m\n",
      "         7         894.3739           20.39m\n",
      "        49        2293.3049           28.89s\n",
      "        48         214.8056           59.21s\n",
      "        16        2396.5402         -32.4177            7.15m\n",
      "        15        2438.9524          70.1120            7.24m\n",
      "        15        2414.8166         120.6673            7.27m\n",
      "        12        2402.3782            9.70m\n",
      "         8         796.4229           19.43m\n",
      "        50        2258.1250            0.00s\n",
      "        17        2390.6905          -4.8941            6.93m\n",
      "        16        2402.6039         -30.2529            7.08m\n",
      "        16        2417.0620         -68.8947            7.08m\n",
      "        50        2268.7229            0.00s\n",
      "        13        2398.5807            9.45m\n",
      "         8         798.4702           20.00m\n",
      "        50        2289.6359            0.00s\n",
      "        18        2398.7172          50.5892            6.73m\n",
      "        17        2431.5907          76.8272            6.84m\n",
      "        17        2407.8047          39.4989            6.86m\n",
      "        49         210.3341           29.66s\n",
      "        14        2394.7915            9.15m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=24.4min\n",
      "        19        2393.3518          -2.9282            6.50m\n",
      "         9         717.7622           19.00m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        18        2417.6489         -37.1883            6.65m\n",
      "        18        2403.8178           2.4426            6.66m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=24.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=24.5min\n",
      "        15        2390.9967            8.89m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         9         719.6823           19.47m\n",
      "        20        2356.2697        -130.0235            6.27m\n",
      "        19        2417.6355          18.7318            6.42m\n",
      "        19        2394.0383         -20.5600            6.44m\n",
      "         1        2455.4177           12.02m\n",
      "         1        2478.3013           12.37m\n",
      "         1        2082.6008         337.6793           10.14m\n",
      "        21        2363.9743          49.1177            6.03m\n",
      "        50         206.7211            0.00s\n",
      "        16        2387.1996            8.62m\n",
      "        20        2387.9819        -100.0963            6.20m\n",
      "        20        2388.2525          -4.6316            6.22m\n",
      "        10         653.1605           18.48m\n",
      "         2        2451.5198           11.32m\n",
      "         2        2474.3988           11.60m\n",
      "         2        1794.3307         335.5285            9.64m\n",
      "        22        2361.9431          10.3229            5.81m\n",
      "        21        2381.2720          -9.6588            5.98m\n",
      "        21        2411.1869         111.4773            5.97m\n",
      "        17        2383.4339            8.30m\n",
      "        10         654.0738           18.84m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=25.1min\n",
      "         3        2447.6581           11.20m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         3        1553.9669         249.9107            9.72m\n",
      "        23        2373.4897          64.5293            5.64m\n",
      "         3        2470.5187           11.79m\n",
      "        22        2416.7331          40.8870            5.78m\n",
      "        22        2364.7097         -47.8605            5.79m\n",
      "        18        2379.6961            8.08m\n",
      "        11         599.7313           18.00m\n",
      "         1        2089.5605         336.9359           10.30m\n",
      "         4        2443.8155           11.16m\n",
      "         4        1344.6703         160.3403            9.45m\n",
      "        24        2365.0048         -15.8449            5.42m\n",
      "        23        2393.7700         -73.3653            5.56m\n",
      "        23        2378.9089          75.2100            5.59m\n",
      "         4        2466.6189           11.47m\n",
      "        11         599.7537           18.36m\n",
      "        19        2375.9468            7.79m\n",
      "         2        1796.8401         325.4159            9.66m\n",
      "         5        1175.5498         143.1790            9.21m\n",
      "         5        2439.9778           10.89m\n",
      "        25        2334.5085        -103.7480            5.21m\n",
      "        24        2401.4588          49.1366            5.36m\n",
      "        24        2380.8266          25.9586            5.37m\n",
      "         5        2462.7247           11.25m\n",
      "         3        1557.9275         255.9776            9.57m\n",
      "        20        2372.2158            7.52m\n",
      "        12         554.8288           17.51m\n",
      "         6        1050.8242         182.5526            8.96m\n",
      "        26        2343.7964          55.2803            5.00m\n",
      "        25        2407.4640          42.3247            5.14m\n",
      "        25        2360.4771         -63.2700            5.15m\n",
      "         6        2436.1368           10.55m\n",
      "        12         553.5607           17.88m\n",
      "         4        1340.0472         139.5991            9.52m\n",
      "         6        2458.8411           11.07m\n",
      "         7         929.5843          73.7164            8.86m\n",
      "        21        2368.5086            7.29m\n",
      "        26        2381.8012         -84.4121            4.94m\n",
      "        27        2349.1712          39.5978            4.80m\n",
      "        26        2364.6316          34.8463            4.96m\n",
      "         7        2432.3018           10.48m\n",
      "         5        1176.7546         175.1955            9.48m\n",
      "         8         841.1906         119.6518            8.69m\n",
      "        13         516.9874           17.08m\n",
      "         7        2454.9536           10.79m\n",
      "        27        2365.6714         -46.1845            4.73m\n",
      "        28        2365.1906          82.2552            4.58m\n",
      "        22        2364.7622            7.04m\n",
      "        27        2352.2726         -31.4033            4.77m\n",
      "         8        2428.4655           10.27m\n",
      "         6        1051.1102         181.1093            9.27m\n",
      "        13         515.2476           17.40m\n",
      "         9         761.6551          67.8608            8.52m\n",
      "        29        2331.0230        -118.6233            4.37m\n",
      "        28        2386.1028         100.0648            4.52m\n",
      "        28        2357.7319          40.0246            4.56m\n",
      "         8        2451.1090           10.56m\n",
      "        23        2361.0557            6.83m\n",
      "         7         925.4986          62.7588            9.16m\n",
      "         9        2424.6277           10.14m\n",
      "        10         685.4487          15.7505            8.38m\n",
      "        29        2360.5736         -84.1343            4.32m\n",
      "        30        2345.3475          75.1617            4.17m\n",
      "        14         484.3502           16.66m\n",
      "        29        2346.9166         -25.0688            4.36m\n",
      "         9        2447.2450           10.32m\n",
      "        24        2357.3841            6.57m\n",
      "         8         842.8213         141.3613            8.83m\n",
      "        11         643.4106         108.7284            8.11m\n",
      "        31        2349.8529          36.0703            3.95m\n",
      "        30        2370.4893          57.9838            4.11m\n",
      "        10        2420.7897            9.84m\n",
      "        14         482.3612           16.91m\n",
      "        30        2356.8895          57.9680            4.14m\n",
      "        10        2443.3965           10.02m\n",
      "         9         760.0066          58.5971            8.56m\n",
      "        32        2334.3654         -44.1196            3.73m\n",
      "        25        2353.6716            6.30m\n",
      "        12         589.8236          13.1099            7.85m\n",
      "        31        2362.5198         -13.6190            3.90m\n",
      "        31        2348.1462         -17.0198            3.93m\n",
      "        11        2416.9808            9.53m\n",
      "        15         457.1564           16.14m\n",
      "        10         687.3320          36.8919            8.29m\n",
      "        11        2439.5372            9.70m\n",
      "        33        2333.7060          15.3791            3.51m\n",
      "        32        2363.4943          22.0634            3.69m\n",
      "        13         560.3465          77.9518            7.64m\n",
      "        26        2349.9868            6.04m\n",
      "        32        2343.6369          -0.0335            3.72m\n",
      "        15         454.9132           16.37m\n",
      "        12        2413.1891            9.31m\n",
      "        11         639.1499          83.1618            8.07m\n",
      "        34        2316.9399         -49.3466            3.30m\n",
      "        33        2375.5045          66.1307            3.48m\n",
      "        12        2435.6777            9.41m\n",
      "        14         515.6260           1.0056            7.45m\n",
      "        33        2340.3105           4.7175            3.51m\n",
      "        27        2346.3332            5.79m\n",
      "        16         433.6741           15.64m\n",
      "        13        2409.4060            9.06m\n",
      "        12         586.9358          30.8340            7.80m\n",
      "        35        2325.0397          50.1781            3.09m\n",
      "        34        2351.1193         -79.4006            3.27m\n",
      "        15         498.1697          71.3809            7.22m\n",
      "        13        2431.8780            9.13m\n",
      "        34        2321.6154         -57.0829            3.30m\n",
      "        16         431.3712           15.85m\n",
      "        28        2342.6782            5.53m\n",
      "        13         555.7914          79.5046            7.60m\n",
      "        36        2305.8047         -59.1071            2.88m\n",
      "        14        2405.6368            8.79m\n",
      "        35        2371.8480         101.1224            3.06m\n",
      "        16         470.4616          11.0831            7.00m\n",
      "        35        2320.9284          15.2019            3.08m\n",
      "        14        2428.0528            8.85m\n",
      "        37        2297.5503         -15.4143            2.67m\n",
      "        29        2338.9890            5.26m\n",
      "        14         511.6573           5.0308            7.39m\n",
      "        36        2344.8526         -89.9143            2.85m\n",
      "        17         413.7099           15.13m\n",
      "        15        2401.8687            8.50m\n",
      "        17         449.0585          21.0056            6.78m\n",
      "        36        2324.4291          31.7906            2.87m\n",
      "        15        2424.2190            8.58m\n",
      "        38        2310.6973          70.3360            2.45m\n",
      "        15         489.8942          61.9582            7.17m\n",
      "        37        2349.7221          37.5093            2.64m\n",
      "        17         410.9959           15.33m\n",
      "        30        2335.2896            4.99m\n",
      "        37        2320.2358           1.0520            2.66m\n",
      "        18         433.7994          39.6968            6.58m\n",
      "        16        2398.1167            8.24m\n",
      "        39        2305.8666          -1.5523            2.24m\n",
      "        16        2420.3984            8.31m\n",
      "        38        2356.1810          43.8228            2.43m\n",
      "        16         460.4584           5.5722            6.96m\n",
      "        19         413.7389           0.4121            6.35m\n",
      "        38        2332.2649          65.9748            2.46m\n",
      "        18         396.4311           14.64m\n",
      "        31        2331.6266            4.74m\n",
      "        17        2394.3541            7.99m\n",
      "        40        2277.9956         -93.9103            2.04m\n",
      "        39        2340.6740         -44.0245            2.23m\n",
      "        17         444.4222          43.3328            6.74m\n",
      "        17        2416.5895            8.04m\n",
      "        39        2314.8161         -52.0114            2.25m\n",
      "        18         393.7817           14.83m\n",
      "        20         389.4595         -13.1906            6.15m\n",
      "        32        2327.9650            4.48m\n",
      "        41        2290.1596          66.2064            1.83m\n",
      "        40        2325.5596         -42.5149            2.02m\n",
      "        18        2390.5879            7.77m\n",
      "        18         424.4227          14.9803            6.55m\n",
      "        40        2310.3761           0.0614            2.04m\n",
      "        21         376.1635          14.8777            5.93m\n",
      "        18        2412.8013            7.81m\n",
      "        19         381.8879           14.16m\n",
      "        42        2287.1183           5.5788            1.63m\n",
      "        33        2324.3085            4.23m\n",
      "        41        2323.6036           9.8556            1.82m\n",
      "        19        2386.8218            7.51m\n",
      "        19         410.2771          24.6126            6.34m\n",
      "        41        2303.4483         -10.0820            1.83m\n",
      "        22         365.6998          11.7995            5.73m\n",
      "        19         377.8577           14.34m\n",
      "        19        2409.0071            7.55m\n",
      "        43        2302.6520          79.7606            1.42m\n",
      "        42        2330.4170          44.9402            1.62m\n",
      "        34        2320.6726            3.98m\n",
      "        20         388.7025         -12.2202            6.13m\n",
      "        42        2297.1008          -7.6495            1.63m\n",
      "        20        2383.0635            7.25m\n",
      "        23         359.3954          34.8674            5.55m\n",
      "        20        2405.2667            7.29m\n",
      "        44        2278.3226         -79.8617            1.22m\n",
      "        20         368.1052           13.69m\n",
      "        43        2310.1729         -63.0530            1.41m\n",
      "        21         376.3489          16.5956            5.92m\n",
      "        35        2317.0999            3.72m\n",
      "        43        2316.3026          94.4229            1.43m\n",
      "        21        2379.3095            7.02m\n",
      "        24         349.5085          11.9867            5.35m\n",
      "        20         363.8609           13.84m\n",
      "        45        2289.8848          63.7190            1.01m\n",
      "        21        2401.4975            7.04m\n",
      "        44        2317.6690          47.7951            1.21m\n",
      "        22         358.8267          -7.2811            5.71m\n",
      "        44        2297.6633         -56.8616            1.22m\n",
      "        36        2313.5049            3.47m\n",
      "        25         331.2947         -21.7839            5.15m\n",
      "        46        2278.5023         -28.0220           48.68s\n",
      "        22        2375.5542            6.79m\n",
      "        45        2312.2564          -3.8504            1.01m\n",
      "        21         356.2238           13.21m\n",
      "        22        2397.7011            6.77m\n",
      "        45        2282.8618         -41.9350            1.02m\n",
      "        23         355.9134          40.1690            5.52m\n",
      "        37        2309.8799            3.22m\n",
      "        26         326.1004          27.1887            4.95m\n",
      "        47        2265.8042         -33.2595           36.50s\n",
      "        46        2309.1794           5.4127           48.37s\n",
      "        21         352.4403           13.35m\n",
      "        23        2371.7865            6.55m\n",
      "        46        2311.8331         133.5748           48.72s\n",
      "        23        2394.0106            6.51m\n",
      "        24         345.0816          16.0913            5.32m\n",
      "        48        2278.9349          69.9377           24.31s\n",
      "        27         317.7259           7.6961            4.75m\n",
      "        38        2306.2500            2.97m\n",
      "        47        2300.9928         -14.9088           36.21s\n",
      "        24        2368.0579            6.30m\n",
      "        47        2288.5356         -75.7337           36.54s\n",
      "        22         344.8473           12.73m\n",
      "        25         331.5044         -10.4538            5.11m\n",
      "        24        2390.2732            6.27m\n",
      "        49        2278.5315          15.6401           12.14s\n",
      "        48        2304.3625          31.0241           24.11s\n",
      "        28         315.2204          33.0496            4.55m\n",
      "        39        2302.6337            2.72m\n",
      "        22         342.0211           12.86m\n",
      "        48        2284.1014          -0.4203           24.36s\n",
      "        25        2364.3508            6.05m\n",
      "        26         323.8197          13.6112            4.92m\n",
      "        25        2386.5206            6.01m\n",
      "        50        2261.9791         -48.8102            0.00s\n",
      "        49        2313.3754          53.7711           12.05s\n",
      "        29         302.0562         -18.6248            4.34m\n",
      "        49        2292.2318          50.0063           12.15s\n",
      "        40        2299.0614            2.47m\n",
      "        23         335.2485           12.25m\n",
      "        27         313.5796           2.6084            4.72m\n",
      "        26        2360.6585            5.80m\n",
      "        26        2382.8001            5.76m\n",
      "        50        2313.1648          16.7699            0.00s\n",
      "        30         297.9101          25.7310            4.14m\n",
      "        50        2276.4169         -46.1082            0.00s\n",
      "        41        2295.4680            2.22m\n",
      "        23         332.2512           12.38m\n",
      "        28         308.5191          21.5873            4.51m\n",
      "        27        2356.9572            5.54m\n",
      "        27        2379.0385            5.50m\n",
      "        31         291.8397          19.6730            3.94m\n",
      "        42        2291.8704            1.97m\n",
      "        29         302.7280          10.1085            4.30m\n",
      "        24         326.1935           11.77m\n",
      "        28        2353.2902            5.29m\n",
      "        28        2375.3271            5.25m\n",
      "        32         281.9203          -9.3723            3.73m\n",
      "        30         295.8623           7.2332            4.10m\n",
      "        43        2288.2866            1.72m\n",
      "        24         323.5850           11.89m\n",
      "        29        2349.6277            5.04m\n",
      "        29        2371.6318            5.00m\n",
      "        33         276.5268           5.0447            3.52m\n",
      "        31         287.0868           0.2654            3.90m\n",
      "        44        2284.7217            1.47m\n",
      "        25         317.8916           11.30m\n",
      "        30        2345.9673            4.79m\n",
      "        30        2367.8906            4.75m\n",
      "        34         267.5940          -1.2597            3.32m\n",
      "        32         277.6650           6.2525            3.70m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=11.3min\n",
      "        25         316.1665           11.42m\n",
      "        45        2281.1442            1.22m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        31        2342.2978            4.54m\n",
      "        31        2364.2278            4.52m\n",
      "        35         261.1966          10.3248            3.12m\n",
      "        33         272.2781           9.4595            3.50m\n",
      "         1        2102.9796         346.0642            9.22m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=11.3min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        46        2277.5851           58.57s\n",
      "        26         310.8478           10.84m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=11.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        32        2338.6441            4.31m\n",
      "        36         253.0707           2.1283            2.92m\n",
      "        32        2360.5447            4.29m\n",
      "         2        1814.8417         334.7174            9.49m\n",
      "        34         262.8321           0.2239            3.31m\n",
      "        26         309.8809           10.97m\n",
      "         1        2077.0295           11.75m\n",
      "        47        2274.0275           43.90s\n",
      "         1        2089.2668           11.63m\n",
      "        33        2334.9649            4.07m\n",
      "        37         249.7855          10.8995            2.72m\n",
      "        33        2356.8639            4.05m\n",
      "         3        1564.6609         243.7897            9.29m\n",
      "        35         256.3562           4.6602            3.11m\n",
      "         2        1776.6882           11.15m\n",
      "        27         303.8718           10.39m\n",
      "        48        2270.4813           29.23s\n",
      "         4        1356.7103         183.3228            8.94m\n",
      "         2        1786.2252           11.23m\n",
      "        38         246.9998          13.1448            2.51m\n",
      "        34        2331.3040            3.82m\n",
      "        34        2353.1961            3.80m\n",
      "        36         250.9274           7.2533            2.91m\n",
      "        27         303.4750           10.50m\n",
      "         3        1526.6975           11.07m\n",
      "        49        2266.9367           14.61s\n",
      "         5        1202.6923         220.5018            8.78m\n",
      "        39         241.6640           0.9142            2.31m\n",
      "         3        1536.8103           10.95m\n",
      "        35        2327.6580            3.58m\n",
      "        35        2349.5517            3.56m\n",
      "        37         244.7977          13.0076            2.71m\n",
      "        28         297.5056            9.94m\n",
      "         4        1324.9138           10.73m\n",
      "        50        2263.4141            0.00s\n",
      "         6        1060.4272         114.1076            8.51m\n",
      "        40         231.3757         -17.0037            2.10m\n",
      "         4        1333.0901           10.73m\n",
      "        36        2324.0142            3.34m\n",
      "        36        2345.8847            3.32m\n",
      "        38         242.1354          17.1512            2.51m\n",
      "        28         297.1180           10.04m\n",
      "         7         946.6940         119.5053            8.33m\n",
      "         5        1157.0323           10.39m\n",
      "        41         226.5463          10.3735            1.90m\n",
      "         5        1163.8005           10.46m\n",
      "        37        2320.3987            3.10m\n",
      "        37        2342.2566            3.08m\n",
      "        39         235.0534          -2.5115            2.30m\n",
      "         8         846.6139          68.1553            8.12m\n",
      "        29         292.0913            9.48m\n",
      "         6        1017.8121           10.11m\n",
      "        42         222.2544           7.6923            1.69m\n",
      "         6        1024.9082           10.21m\n",
      "        38        2316.7606            2.86m\n",
      "         9         776.4391         118.3836            7.92m\n",
      "        38        2338.5788            2.85m\n",
      "        40         230.3817           3.3195            2.10m\n",
      "        29         291.5419            9.59m\n",
      "         7         902.8449           10.00m\n",
      "        10         707.3135          64.6473            7.78m\n",
      "        43         220.3964          16.9497            1.48m\n",
      "         7         909.4660           10.08m\n",
      "        39        2313.1404            2.62m\n",
      "        39        2334.9229            2.61m\n",
      "        30         285.9579            9.04m\n",
      "        41         225.0051           5.5767            1.90m\n",
      "         8         806.1667            9.84m\n",
      "        11         647.5266          47.2990            7.58m\n",
      "         8         813.3981            9.83m\n",
      "        44         216.3449           5.6926            1.28m\n",
      "        40        2309.5032            2.38m\n",
      "        40        2331.2848            2.37m\n",
      "        30         286.3052            9.12m\n",
      "        42         217.9900          -4.0228            1.69m\n",
      "         9         725.5209            9.61m\n",
      "        12         607.1931          76.8806            7.38m\n",
      "         9         733.4991            9.61m\n",
      "        41        2305.9000            2.14m\n",
      "        45         213.0053          11.9298            1.07m\n",
      "        41        2327.6586            2.14m\n",
      "        31         281.3927            8.59m\n",
      "        13         558.2363           3.6806            7.27m\n",
      "        43         215.6045          19.1035            1.49m\n",
      "        10         659.2964            9.47m\n",
      "        10         665.1624            9.44m\n",
      "        42        2302.3327            1.90m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=13.7min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        42        2324.0142            1.90m\n",
      "        31         281.0224            8.68m\n",
      "        46         204.5134         -14.3781           51.74s\n",
      "        14         526.1067          40.6828            7.07m\n",
      "        44         208.5830          -3.2434            1.29m\n",
      "        11         602.7057            9.29m\n",
      "        11         607.6004            9.25m\n",
      "        43        2298.7805            1.67m\n",
      "        15         501.3332          44.3412            6.93m\n",
      "         1        2109.7933           13.13m\n",
      "        43        2320.3686            1.67m\n",
      "        32         276.3191            8.17m\n",
      "        47         199.4426           6.0185           39.11s\n",
      "        12         556.1854            9.17m\n",
      "        45         203.9913           5.0244            1.08m\n",
      "        44        2295.2176            1.43m\n",
      "        12         559.1265            9.16m\n",
      "        16         469.2162          -3.3815            6.82m\n",
      "         2        1804.5073           12.71m\n",
      "        32         276.5907            8.26m\n",
      "        44        2316.7810            1.43m\n",
      "        48         199.3772          22.3887           26.28s\n",
      "        13         517.1186            8.98m\n",
      "        46         203.0942          15.5473           52.17s\n",
      "        17         448.5211          28.6258            6.66m\n",
      "        45        2291.6355            1.20m\n",
      "        13         518.3084            8.99m\n",
      "         3        1553.7940           12.38m\n",
      "        45        2313.1641            1.20m\n",
      "        33         270.8771            7.75m\n",
      "        49         195.1474           1.3031           13.17s\n",
      "        14         483.4243            8.74m\n",
      "        18         437.4111          48.1524            6.47m\n",
      "        47         196.4427          -5.9118           39.27s\n",
      "        46        2288.0846           57.48s\n",
      "        14         484.3489            8.72m\n",
      "        33         272.8376            7.80m\n",
      "         4        1347.0738           11.69m\n",
      "        46        2309.5789           57.33s\n",
      "        19         414.5547          -9.7871            6.26m\n",
      "        50         187.7751          -5.9845            0.00s\n",
      "        15         454.3249            8.50m\n",
      "        48         191.9551           4.6574           26.32s\n",
      "        47        2284.5389           43.09s\n",
      "        15         454.3178            8.44m\n",
      "         5        1177.1619           11.15m\n",
      "        47        2306.0268           42.98s\n",
      "        34         266.5791            7.29m\n",
      "        20         396.3105           1.8415            6.06m\n",
      "        16         429.1839            8.29m\n",
      "        48        2280.9677           28.72s\n",
      "        34         268.8786            7.34m\n",
      "        16         428.1110            8.20m\n",
      "         6        1036.5568           10.79m\n",
      "        49         187.8590           7.0041           13.20s\n",
      "        48        2302.4228           28.63s\n",
      "        21         389.5801          50.9238            5.87m\n",
      "        17         407.7032            8.04m\n",
      "         7         918.9255           10.43m\n",
      "        17         406.6694            7.94m\n",
      "        49        2277.4431           14.36s\n",
      "        35         261.8634            6.83m\n",
      "        49        2298.8508           14.31s\n",
      "        50         183.2270          -0.9846            0.00s\n",
      "        22         373.9046           6.5349            5.67m\n",
      "        18         388.7102            7.79m\n",
      "        50        2273.8982            0.00s\n",
      "        35         265.4036            6.88m\n",
      "         8         821.7765           10.11m\n",
      "        18         387.0945            7.71m\n",
      "        50        2295.2898            0.00s\n",
      "        23         359.2009           5.5418            5.47m\n",
      "        19         372.5092            7.52m\n",
      "        24         349.4991          14.1392            5.25m\n",
      "         9         740.2504            9.81m\n",
      "        36         256.0947            6.37m\n",
      "        19         370.0601            7.44m\n",
      "        25         340.6948          14.8972            5.04m\n",
      "        20         357.5084            7.25m\n",
      "        36         259.9582            6.41m\n",
      "        10         673.0737            9.47m\n",
      "        20         355.5412            7.18m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=12.3min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        26         331.3681           7.2877            4.85m\n",
      "        37         251.7528            5.91m\n",
      "        21         343.8643            7.03m\n",
      "        11         616.3399            9.24m\n",
      "        21         340.8250            6.97m\n",
      "        27         315.0797         -13.5999            4.65m\n",
      "        37         255.6804            5.95m\n",
      "        22         331.6098            6.78m\n",
      "        12         567.8928            8.99m\n",
      "        22         328.6406            6.72m\n",
      "         1        2445.9574           3.6600            3.88m\n",
      "        28         309.7142          18.0991            4.45m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=12.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        38         247.9171            5.45m\n",
      "        13         525.7147            8.73m\n",
      "        23         318.7419            6.55m\n",
      "        23         317.0654            6.51m\n",
      "        29         300.6605           4.9950            4.26m\n",
      "        38         252.2796            5.48m\n",
      "        14         490.0261            8.47m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=13.4min\n",
      "        24         306.5603            6.32m\n",
      "         2        2452.5058          46.2368            3.49m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=13.4min\n",
      "        24         306.9867            6.26m\n",
      "        30         295.8424          17.0001            4.06m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        2455.3514           3.6538            3.93m\n",
      "        39         243.4955            5.00m\n",
      "        15         458.5274            8.27m\n",
      "        25         297.6386            6.12m\n",
      "        31         288.0615          12.6817            3.88m\n",
      "        25         297.7067            6.06m\n",
      "        39         247.9336            5.04m\n",
      "        16         431.9966            8.08m\n",
      "         3        2454.8487          29.3702            3.13m\n",
      "         1        2467.6376           3.7859            4.25m\n",
      "        32         280.1799          -0.5336            3.69m\n",
      "        26         288.5278            5.88m\n",
      "        26         288.5353            5.83m\n",
      "         2        2459.5262          36.7607            3.65m\n",
      "         1        2444.2339            5.21m\n",
      "        40         240.2163            4.56m\n",
      "        17         410.0559            7.85m\n",
      "        33         277.1252          15.4855            3.49m\n",
      "        27         280.3954            5.64m\n",
      "        27         278.9917            5.60m\n",
      "        40         244.2809            4.58m\n",
      "         4        2431.0606         -75.2252            2.68m\n",
      "        34         270.4026           7.1096            3.29m\n",
      "         2        2474.7241          48.5730            3.69m\n",
      "        18         389.8398            7.61m\n",
      "        28         271.9877            5.41m\n",
      "         3        2457.6611          12.5473            3.17m\n",
      "        28         269.6484            5.37m\n",
      "        41         236.9988            4.10m\n",
      "        35         266.7983          14.5914            3.08m\n",
      "         2        2440.1548            4.42m\n",
      "        19         372.9279            7.37m\n",
      "        41         240.9787            4.12m\n",
      "        29         264.5206            5.17m\n",
      "        29         263.0663            5.13m\n",
      "         5        2422.8286         -13.0136            2.22m\n",
      "        36         257.7620          -6.1809            2.89m\n",
      "         3        2467.0387         -10.4972            3.22m\n",
      "        20         358.4525            7.13m\n",
      "         4        2428.4100         -96.9776            2.71m\n",
      "        30         258.2197            4.93m\n",
      "        42         232.1748            3.65m\n",
      "        37         252.8619           6.4445            2.69m\n",
      "        30         256.1180            4.90m\n",
      "        21         343.4425            6.91m\n",
      "         3        2436.0839            3.86m\n",
      "        42         237.7537            3.67m\n",
      "         6        2437.5071          78.6524            1.77m\n",
      "         4        2452.8198         -36.6696            2.75m\n",
      "        38         249.5732          14.2053            2.49m\n",
      "        31         251.1476            4.71m\n",
      "        31         246.5989            4.67m\n",
      "        22         331.6965            6.66m\n",
      "         5        2428.3619          19.8165            2.25m\n",
      "        43         228.1544            3.19m\n",
      "        39         240.1859          -6.2279            2.29m\n",
      "        32         244.9127            4.47m\n",
      "        23         320.7725            6.44m\n",
      "        32         239.9177            4.44m\n",
      "        43         234.1688            3.21m\n",
      "         7        2414.7643         -71.1841            1.33m\n",
      "         4        2432.0210            3.29m\n",
      "         5        2473.7535         103.9627            2.28m\n",
      "        40         232.0878          -5.6495            2.09m\n",
      "        33         238.6428            4.23m\n",
      "        24         309.9802            6.22m\n",
      "         6        2442.0409          74.6449            1.80m\n",
      "        33         233.2118            4.20m\n",
      "        44         223.0500            2.73m\n",
      "        41         228.4997          10.3964            1.89m\n",
      "        25         300.5052            5.99m\n",
      "        34         230.4032            3.99m\n",
      "         8        2424.6027          59.1803           53.07s\n",
      "        44         229.9366            2.75m\n",
      "        34         226.9119            3.97m\n",
      "         6        2458.2472         -41.9174            1.82m\n",
      "        42         227.2087          18.0373            1.68m\n",
      "         5        2427.9661            2.74m\n",
      "         7        2412.9650         -96.4720            1.35m\n",
      "        26         289.6742            5.78m\n",
      "        35         223.7855            3.75m\n",
      "        45         220.2571            2.28m\n",
      "        35         219.4926            3.73m\n",
      "        43         218.7907          -9.1054            1.48m\n",
      "         9        2417.8589          -7.2498           26.54s\n",
      "        45         226.0906            2.29m\n",
      "        27         281.5881            5.55m\n",
      "         7        2452.7224          -1.9736            1.36m\n",
      "        36         216.7747            3.52m\n",
      "        36         212.2088            3.50m\n",
      "        44         213.7825           5.1545            1.27m\n",
      "         8        2432.7156          98.9593           53.99s\n",
      "         6        2423.9195            2.19m\n",
      "        46         216.0151            1.82m\n",
      "        28         271.4607            5.32m\n",
      "        37         210.5020            3.28m\n",
      "        37         207.3204            3.26m\n",
      "        10        2393.4563         -77.9884            0.00s\n",
      "        45         208.6015          -0.4277            1.07m\n",
      "        46         219.1483            1.83m\n",
      "         8        2442.3484         -21.4816           54.33s\n",
      "        29         262.6686            5.10m\n",
      "         9        2423.2231         -18.1458           27.04s\n",
      "        38         204.9069            3.04m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 4.7min\n",
      "        46         205.7640          11.5027           51.63s\n",
      "        38         202.1244            3.03m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         7        2419.8805            1.65m\n",
      "        47         214.2605            1.37m\n",
      "        30         255.7164            4.88m\n",
      "        47         217.0619            1.38m\n",
      "        39         199.9110            2.80m\n",
      "         9        2463.9997         106.6376           27.31s\n",
      "        47         199.9419          -2.9511           39.01s\n",
      "        39         197.2529            2.79m\n",
      "        10        2408.5980         -38.7260            0.00s\n",
      "        31         248.0592            4.66m\n",
      "        48         209.1651           54.83s\n",
      "        40         195.3879            2.55m\n",
      "        48         199.1795          20.9567           26.11s\n",
      "         1        2455.2051            4.98m\n",
      "        40         191.4877            2.54m\n",
      "         8        2415.8497            1.10m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 4.8min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        32         241.2617            4.42m\n",
      "        48         214.7559           55.01s\n",
      "        10        2443.2644         -62.9188            0.00s\n",
      "        49         194.7764           7.0186           13.11s\n",
      "        41         190.0216            2.31m\n",
      "        41         187.1748            2.30m\n",
      "        33         235.2153            4.19m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 4.8min\n",
      "        49         205.9101           27.42s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        50         190.3157          -0.1274            0.00s\n",
      "         2        2451.1073            4.41m\n",
      "        42         186.0834            2.06m\n",
      "         9        2411.8268           32.92s\n",
      "        49         212.1848           27.51s\n",
      "        42         183.4374            2.05m\n",
      "        34         228.0036            3.96m\n",
      "         1        2478.0763            5.12m\n",
      "        43         182.1871            1.81m\n",
      "         1        2061.8234         346.4004            4.01m\n",
      "        50         203.0638            0.00s\n",
      "        43         177.4407            1.80m\n",
      "        35         221.7025            3.73m\n",
      "        50         209.3724            0.00s\n",
      "         3        2447.0176            3.85m\n",
      "        10        2407.8099            0.00s\n",
      "        44         178.4645            1.55m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=23.2min\n",
      "        44         172.4936            1.55m\n",
      "         2        2473.9413            4.49m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        36         215.2443            3.49m\n",
      "         2        1760.2523         349.9139            3.57m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=23.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 5.8min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        45         173.6806            1.30m\n",
      "        37         210.1893            3.26m\n",
      "        45         167.6090            1.30m\n",
      "         4        2442.9362            3.29m\n",
      "         1        2069.7442         345.6353            4.03m\n",
      "         3        1507.6782         262.0899            3.14m\n",
      "        38         205.7868            3.01m\n",
      "        46         169.7218            1.05m\n",
      "         3        2469.8144            3.95m\n",
      "         1        2078.7907         358.0818            4.06m\n",
      "        46         163.1838            1.04m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=12.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        2059.8387            5.07m\n",
      "        39         200.1678            2.77m\n",
      "        47         165.3515           47.25s\n",
      "         2        1764.4085         339.4020            3.62m\n",
      "        47         159.8119           47.05s\n",
      "         5        2438.8630            2.76m\n",
      "         4        1288.7066         167.9275            2.71m\n",
      "         2        1774.3536         354.8637            3.68m\n",
      "         4        2465.6963            3.39m\n",
      "        40         195.6650            2.53m\n",
      "        48         161.4530           31.71s\n",
      "        48         156.4314           31.51s\n",
      "         1        2069.0535            4.94m\n",
      "         2        1743.2511            4.48m\n",
      "         3        1513.5138         273.4120            3.17m\n",
      "        41         190.9497            2.28m\n",
      "         5        1114.7693         157.2626            2.25m\n",
      "         3        1513.8206         246.3461            3.20m\n",
      "         6        2434.7979            2.21m\n",
      "        49         157.0725           15.92s\n",
      "        49         152.5315           15.85s\n",
      "         5        2461.5839            2.83m\n",
      "        42         186.8808            2.04m\n",
      "         2        1751.5764            4.42m\n",
      "         4        1287.6070         144.1392            2.71m\n",
      "        50         153.3982            0.00s\n",
      "         3        1485.0926            3.90m\n",
      "        50         148.7668            0.00s\n",
      "         6         981.7054         176.1026            1.80m\n",
      "         4        1299.9652         200.7600            2.72m\n",
      "        43         183.1243            1.79m\n",
      "         7        2430.7410            1.65m\n",
      "         5        1117.3095         178.8342            2.24m\n",
      "         6        2457.4803            2.25m\n",
      "        44         179.3639            1.54m\n",
      "         3        1492.4591            3.83m\n",
      "         7         860.4662          95.8454            1.34m\n",
      "         5        1137.9180         221.3017            2.24m\n",
      "         4        1273.9079            3.31m\n",
      "        45         175.5975            1.29m\n",
      "         8        2426.6920            1.10m\n",
      "         6         986.6351         185.6578            1.79m\n",
      "         8         765.8694         106.0086           53.61s\n",
      "         7        2453.3851            1.68m\n",
      "         6         990.3471         121.1035            1.79m\n",
      "         4        1279.8820            3.27m\n",
      "        46         171.9432            1.03m\n",
      "         5        1100.6816            2.75m\n",
      "         7         858.6793          71.9130            1.34m\n",
      "         9        2422.6513           32.87s\n",
      "        47         168.4507           46.68s\n",
      "         9         684.7788          77.1750           26.73s\n",
      "         7         873.1534         121.6197            1.34m\n",
      "         8        2449.2981            1.12m\n",
      "         5        1104.7761            2.73m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=14.9min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=14.9min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         6         958.3574            2.20m\n",
      "        48         164.1672           31.25s\n",
      "         8         770.8719         134.4314           53.65s\n",
      "        10         607.8323          22.0976            0.00s\n",
      "         1        2446.1760           3.5610            1.87m\n",
      "        10        2418.6183            0.00s\n",
      "         8         770.2526          74.0920           53.73s\n",
      "        49         159.6268           15.71s\n",
      "         2        2452.9246          46.0293            1.59m\n",
      "         9        2445.2194           33.56s\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 4.7min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         6         960.9472            2.20m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 5.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        2088.4106            5.10m\n",
      "         9         688.1177          69.1406           26.88s\n",
      "         7         840.6943            1.65m\n",
      "         3        2455.4530          29.1841            1.42m\n",
      "         1        2455.5599           3.5550            1.76m\n",
      "        50         156.1590            0.00s\n",
      "         9         699.0587         122.4168           27.01s\n",
      "         1        2467.8921           3.6527            1.77m\n",
      "         4        2431.9064         -75.4094            1.20m\n",
      "         2        2459.9070          36.5588            1.53m\n",
      "         2        2475.2228          48.3068            1.55m\n",
      "        10        2441.1483            0.00s\n",
      "        10         613.6992          38.3737            0.00s\n",
      "         5        2423.8540         -13.3643            1.00m\n",
      "         3        2458.3028          12.3200            1.31m\n",
      "         7         842.1873            1.65m\n",
      "         2        1767.8668            4.52m\n",
      "         3        2467.7947         -10.6178            1.35m\n",
      "         8         742.6953            1.11m\n",
      "        10         628.9586          56.6713            0.00s\n",
      "         6        2438.8017          78.6175           48.03s\n",
      "         4        2429.2341         -97.2984            1.12m\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 4.8min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 5.9min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4        2453.7824         -37.0100            1.17m\n",
      "         7        2416.2130         -71.6010           35.98s\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 4.8min\n",
      "         5        2429.4341          19.6846           57.66s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         5        2474.9147         103.7698           58.60s\n",
      "         1        2444.4148            2.14m\n",
      "         1        2455.4177            2.12m\n",
      "         8        2426.3003          59.1665           23.76s\n",
      "         6        2443.3418          74.4001           46.17s\n",
      "         8         744.0771            1.11m\n",
      "         1        2478.3013            2.10m\n",
      "         3        1505.9009            3.97m\n",
      "         6        2459.6434         -42.2070           46.59s\n",
      "         9         661.3501           33.22s\n",
      "         2        2440.5421            1.88m\n",
      "         2        2451.5198            1.82m\n",
      "         9        2419.7688          -7.5125           11.84s\n",
      "         7        2414.4508         -96.8138           34.90s\n",
      "         7        2454.4281          -2.0937           34.94s\n",
      "         2        2474.3988            1.85m\n",
      "        10        2395.5178         -78.3816            0.00s\n",
      "         3        2436.6861            1.66m\n",
      "         3        2447.6581            1.62m\n",
      "         8        2434.4842          98.8868           23.16s\n",
      "         8        2444.1870         -21.7983           23.18s\n",
      "         3        2470.5187            1.65m\n",
      "         9         662.1831           33.16s\n",
      "         9        2425.1700         -18.4590           11.56s\n",
      "         4        1291.4759            3.37m\n",
      "         4        2432.8538            1.41m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 2.2min\n",
      "         4        2443.8155            1.39m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         9        2466.0805         106.6654           11.56s\n",
      "        10         593.7164            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=14.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         4        2466.6189            1.43m\n",
      "        10        2410.7814         -38.8520            0.00s\n",
      "         1        2082.6008         337.6793            1.82m\n",
      "         5        2429.0362            1.17m\n",
      "        10        2445.5242         -63.1684            0.00s\n",
      "         5        2439.9778            1.16m\n",
      "         1        2089.5605         336.9359            1.72m\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 5.9min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         5        2462.7247            1.20m\n",
      "         2        1794.3307         335.5285            1.61m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 2.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         2        1796.8401         325.4159            1.59m\n",
      "         6        2436.1368           56.13s\n",
      "         6        2425.2232           56.96s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 2.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        10         594.4152            0.00s\n",
      "         1        2102.9796         346.0642            1.88m\n",
      "         5        1114.9377            2.84m\n",
      "         3        1553.9669         249.9107            1.43m\n",
      "         6        2458.8411           57.94s\n",
      "         3        1557.9275         255.9776            1.38m\n",
      "         1        2077.0295            2.11m\n",
      "         7        2432.3018           42.06s\n",
      "         7        2421.3893           42.73s\n",
      "         1        2089.2668            2.10m\n",
      "         2        1814.8417         334.7174            1.63m\n",
      "         4        1344.6703         160.3403            1.21m\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 5.9min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4        1340.0472         139.5991            1.20m\n",
      "         7        2454.9536           43.36s\n",
      "         2        1776.6882            1.87m\n",
      "         8        2428.4655           28.11s\n",
      "         8        2417.5931           28.62s\n",
      "         3        1564.6609         243.7897            1.39m\n",
      "         2        1786.2252            1.89m\n",
      "         5        1175.5498         143.1790            1.01m\n",
      "         5        1176.7546         175.1955           59.91s\n",
      "         1        2109.7933            2.20m\n",
      "         8        2451.1090           28.84s\n",
      "         6         970.5020            2.27m\n",
      "         4        1356.7103         183.3228            1.18m\n",
      "         3        1526.6975            1.65m\n",
      "         9        2424.6277           14.02s\n",
      "         9        2413.7603           14.24s\n",
      "         6        1050.8242         182.5526           47.80s\n",
      "         3        1536.8103            1.63m\n",
      "         6        1051.1102         181.1093           47.48s\n",
      "         5        1202.6923         220.5018           58.19s\n",
      "         9        2447.2450           14.25s\n",
      "         2        1804.5073            1.89m\n",
      "         4        1324.9138            1.38m\n",
      "         7         929.5843          73.7164           35.55s\n",
      "        10        2420.7897            0.00s\n",
      "        10        2409.9542            0.00s\n",
      "         4        1333.0901            1.39m\n",
      "         7         925.4986          62.7588           35.34s\n",
      "         6        1060.4272         114.1076           46.19s\n",
      "         8         841.1906         119.6518           23.47s\n",
      "        10        2443.3965            0.00s\n",
      "         3        1553.7940            1.65m\n",
      "         5        1157.0323            1.14m\n",
      "         8         842.8213         141.3613           23.26s\n",
      "         5        1163.8005            1.15m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.6min\n",
      "         7         851.8709            1.69m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.7min\n",
      "         7         946.6940         119.5053           34.35s\n",
      "         9         761.6551          67.8608           11.66s\n",
      "         4        1347.0738            1.36m\n",
      "         9         760.0066          58.5971           11.46s\n",
      "         6        1017.8121           53.73s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.6min\n",
      "         8         846.6139          68.1553           22.44s\n",
      "         6        1024.9082           54.02s\n",
      "        10         685.4487          15.7505            0.00s\n",
      "        10         687.3320          36.8919            0.00s\n",
      "         5        1177.1619            1.10m\n",
      "         7         902.8449           39.73s\n",
      "         9         776.4391         118.3836           11.05s\n",
      "         7         909.4660           39.88s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 2.1min\n",
      "         8         752.4335            1.10m\n",
      "         6        1036.5568           52.05s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 2.1min\n",
      "        10         707.3135          64.6473            0.00s\n",
      "         8         806.1667           26.18s\n",
      "         8         813.3981           26.09s\n",
      "         7         918.9255           38.02s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 2.0min\n",
      "         9         725.5209           12.83s\n",
      "         9         733.4991           12.76s\n",
      "         8         821.7765           24.87s\n",
      "        10         659.2964            0.00s\n",
      "         9         670.3338           32.32s\n",
      "        10         665.1624            0.00s\n",
      "         9         740.2504           12.20s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.3min\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.3min\n",
      "        10         673.0737            0.00s\n",
      "        10         601.7760            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 5.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1        2083.6035         351.5823           17.34m\n",
      "         2        1773.0446         287.8226           16.90m\n",
      "         3        1531.5958         285.5786           16.63m\n",
      "         4        1328.0216         209.8748           16.33m\n",
      "         5        1136.9928          64.4782           16.03m\n",
      "         6        1014.8479         199.0301           15.84m\n",
      "         7         901.8975         113.3199           15.63m\n",
      "         8         820.3192         139.4229           15.32m\n",
      "         9         731.6378          32.9100           14.90m\n",
      "        10         670.3462          78.4470           14.51m\n",
      "        11         616.7052          52.3679           14.11m\n",
      "        12         569.8056          37.7898           13.72m\n",
      "        13         532.2366          37.5510           13.35m\n",
      "        14         504.4915          46.5728           12.98m\n",
      "        15         482.2191          47.8065           12.60m\n",
      "        16         446.7208         -28.7017           12.24m\n",
      "        17         433.6444          41.8096           11.87m\n",
      "        18         417.9447          24.0517           11.50m\n",
      "        19         407.3641          33.8291           11.14m\n",
      "        20         394.6751          12.3917           10.77m\n",
      "        21         374.1953         -19.2768           10.41m\n",
      "        22         369.4860          30.8945           10.06m\n",
      "        23         358.2804           6.5740            9.70m\n",
      "        24         348.5391           9.1899            9.35m\n",
      "        25         339.8523           5.7614            9.00m\n",
      "        26         333.6172          13.9779            8.65m\n",
      "        27         325.5069           4.0678            8.30m\n",
      "        28         316.4680           1.6027            7.95m\n",
      "        29         315.6141          26.9752            7.60m\n",
      "        30         303.9532         -18.0633            7.25m\n",
      "        31         300.4588          12.4586            6.89m\n",
      "        32         292.4479          -6.2744            6.53m\n",
      "        33         287.9156          16.9802            6.18m\n",
      "        34         285.5833          10.0028            5.82m\n",
      "        35         280.7332           2.9689            5.47m\n",
      "        36         273.3023         -13.0958            5.11m\n",
      "        37         274.0245          25.3900            4.75m\n",
      "        38         269.2474           1.3827            4.39m\n",
      "        39         266.0822           3.7589            4.03m\n",
      "        40         262.4221           8.9915            3.67m\n",
      "        41         253.5590          -8.2800            3.31m\n",
      "        42         251.8058          13.9258            2.95m\n",
      "        43         247.2449           4.0176            2.59m\n",
      "        44         244.9248           8.9042            2.22m\n",
      "        45         240.0252           0.4233            1.85m\n",
      "        46         233.9874          -3.6583            1.49m\n",
      "        47         232.1615          13.8763            1.12m\n",
      "        48         227.5227          -4.0304           44.76s\n",
      "        49         228.0968          17.9995           22.41s\n",
      "        50         222.9171          -5.7700            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingRegressor(min_samples_leaf=7,\n",
       "                                                 min_samples_split=14,\n",
       "                                                 random_state=42, verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [20],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [70],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]}],\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingRegressor(min_samples_leaf=7,\n",
       "                                                 min_samples_split=14,\n",
       "                                                 random_state=42, verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [20],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [70],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]}],\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(min_samples_leaf=7, min_samples_split=14,\n",
       "                          random_state=42, verbose=2)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(min_samples_leaf=7, min_samples_split=14,\n",
       "                          random_state=42, verbose=2)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingRegressor(min_samples_leaf=7,\n",
       "                                                 min_samples_split=14,\n",
       "                                                 random_state=42, verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'learning_rate': [0.001, 0.1], 'max_depth': [20],\n",
       "                          'max_features': [1.0], 'n_estimators': [50],\n",
       "                          'subsample': [0.8, 1.0]},\n",
       "                         {'learning_rate': [0.001, 0.1], 'max_depth': [100],\n",
       "                          'max_features': ['sqrt'], 'n_estimators': [50],\n",
       "                          'subsample': [0.8, 1.0]},\n",
       "                         {'learning_rate': [0.001, 0.1], 'max_depth': [70],\n",
       "                          'max_features': [1.0], 'n_estimators': [10],\n",
       "                          'subsample': [0.8, 1.0]},\n",
       "                         {'learning_rate': [0.001, 0.1], 'max_depth': [100],\n",
       "                          'max_features': ['sqrt'], 'n_estimators': [10],\n",
       "                          'subsample': [0.8, 1.0]}],\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, response_method='predict'),\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1192.335052</td>\n",
       "      <td>4.454699</td>\n",
       "      <td>24.065205</td>\n",
       "      <td>0.315125</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 20, 'max...</td>\n",
       "      <td>-2316.155829</td>\n",
       "      <td>-2292.261900</td>\n",
       "      <td>-2249.587536</td>\n",
       "      <td>-2286.001755</td>\n",
       "      <td>27.534542</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1441.229446</td>\n",
       "      <td>4.380348</td>\n",
       "      <td>25.188702</td>\n",
       "      <td>0.477633</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 20, 'max...</td>\n",
       "      <td>-2315.840445</td>\n",
       "      <td>-2291.895284</td>\n",
       "      <td>-2249.760211</td>\n",
       "      <td>-2285.831980</td>\n",
       "      <td>27.315711</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1221.315350</td>\n",
       "      <td>1.434354</td>\n",
       "      <td>18.360734</td>\n",
       "      <td>0.135439</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 20, 'max_f...</td>\n",
       "      <td>-602.879907</td>\n",
       "      <td>-590.303962</td>\n",
       "      <td>-567.286072</td>\n",
       "      <td>-586.823314</td>\n",
       "      <td>14.738079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1411.918435</td>\n",
       "      <td>52.394547</td>\n",
       "      <td>18.384771</td>\n",
       "      <td>0.593044</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 20, 'max_f...</td>\n",
       "      <td>-616.910621</td>\n",
       "      <td>-604.837185</td>\n",
       "      <td>-592.255086</td>\n",
       "      <td>-604.667631</td>\n",
       "      <td>10.066294</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>605.676696</td>\n",
       "      <td>2.447325</td>\n",
       "      <td>73.078290</td>\n",
       "      <td>0.737162</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2320.359644</td>\n",
       "      <td>-2297.024085</td>\n",
       "      <td>-2253.553709</td>\n",
       "      <td>-2290.312479</td>\n",
       "      <td>27.683238</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>721.158717</td>\n",
       "      <td>6.471939</td>\n",
       "      <td>87.468974</td>\n",
       "      <td>2.847364</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2319.231686</td>\n",
       "      <td>-2295.597175</td>\n",
       "      <td>-2252.595126</td>\n",
       "      <td>-2289.141329</td>\n",
       "      <td>27.584612</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>662.171662</td>\n",
       "      <td>1.531661</td>\n",
       "      <td>79.043533</td>\n",
       "      <td>2.139171</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-601.621072</td>\n",
       "      <td>-588.631223</td>\n",
       "      <td>-572.459033</td>\n",
       "      <td>-587.570443</td>\n",
       "      <td>11.928958</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>795.735319</td>\n",
       "      <td>4.882697</td>\n",
       "      <td>95.261302</td>\n",
       "      <td>1.202407</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-604.230360</td>\n",
       "      <td>-598.743866</td>\n",
       "      <td>-580.853467</td>\n",
       "      <td>-594.609231</td>\n",
       "      <td>9.981356</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>270.951290</td>\n",
       "      <td>2.982395</td>\n",
       "      <td>16.301711</td>\n",
       "      <td>0.381458</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 70, 'max...</td>\n",
       "      <td>-2456.093940</td>\n",
       "      <td>-2433.669172</td>\n",
       "      <td>-2388.440344</td>\n",
       "      <td>-2426.067819</td>\n",
       "      <td>28.137611</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>331.826775</td>\n",
       "      <td>3.128227</td>\n",
       "      <td>18.265487</td>\n",
       "      <td>0.108237</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 70, 'max...</td>\n",
       "      <td>-2456.027120</td>\n",
       "      <td>-2433.550866</td>\n",
       "      <td>-2388.447093</td>\n",
       "      <td>-2426.008359</td>\n",
       "      <td>28.100202</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>269.909204</td>\n",
       "      <td>0.995599</td>\n",
       "      <td>15.977690</td>\n",
       "      <td>0.130974</td>\n",
       "      <td>0.1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 70, 'max_f...</td>\n",
       "      <td>-866.380545</td>\n",
       "      <td>-837.564872</td>\n",
       "      <td>-813.668724</td>\n",
       "      <td>-839.204713</td>\n",
       "      <td>21.550728</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>327.816767</td>\n",
       "      <td>9.056692</td>\n",
       "      <td>15.095117</td>\n",
       "      <td>5.588393</td>\n",
       "      <td>0.1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 70, 'max_f...</td>\n",
       "      <td>-876.514064</td>\n",
       "      <td>-845.413807</td>\n",
       "      <td>-826.294196</td>\n",
       "      <td>-849.407356</td>\n",
       "      <td>20.695734</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>117.546754</td>\n",
       "      <td>1.190391</td>\n",
       "      <td>15.718472</td>\n",
       "      <td>0.767186</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2457.280547</td>\n",
       "      <td>-2435.029909</td>\n",
       "      <td>-2389.777880</td>\n",
       "      <td>-2427.362779</td>\n",
       "      <td>28.086072</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>141.814235</td>\n",
       "      <td>1.331566</td>\n",
       "      <td>16.470578</td>\n",
       "      <td>0.433369</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2457.102358</td>\n",
       "      <td>-2434.712817</td>\n",
       "      <td>-2389.420032</td>\n",
       "      <td>-2427.078402</td>\n",
       "      <td>28.153597</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>113.418404</td>\n",
       "      <td>2.564586</td>\n",
       "      <td>12.145719</td>\n",
       "      <td>0.748580</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-880.374256</td>\n",
       "      <td>-850.721003</td>\n",
       "      <td>-830.949707</td>\n",
       "      <td>-854.014989</td>\n",
       "      <td>20.311479</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>124.166940</td>\n",
       "      <td>3.331511</td>\n",
       "      <td>10.004712</td>\n",
       "      <td>0.988997</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-866.819729</td>\n",
       "      <td>-846.442768</td>\n",
       "      <td>-820.086015</td>\n",
       "      <td>-844.449504</td>\n",
       "      <td>19.130949</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     1192.335052      4.454699        24.065205        0.315125   \n",
       "1     1441.229446      4.380348        25.188702        0.477633   \n",
       "2     1221.315350      1.434354        18.360734        0.135439   \n",
       "3     1411.918435     52.394547        18.384771        0.593044   \n",
       "4      605.676696      2.447325        73.078290        0.737162   \n",
       "5      721.158717      6.471939        87.468974        2.847364   \n",
       "6      662.171662      1.531661        79.043533        2.139171   \n",
       "7      795.735319      4.882697        95.261302        1.202407   \n",
       "8      270.951290      2.982395        16.301711        0.381458   \n",
       "9      331.826775      3.128227        18.265487        0.108237   \n",
       "10     269.909204      0.995599        15.977690        0.130974   \n",
       "11     327.816767      9.056692        15.095117        5.588393   \n",
       "12     117.546754      1.190391        15.718472        0.767186   \n",
       "13     141.814235      1.331566        16.470578        0.433369   \n",
       "14     113.418404      2.564586        12.145719        0.748580   \n",
       "15     124.166940      3.331511        10.004712        0.988997   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features param_n_estimators  \\\n",
       "0                0.001              20                1.0                 50   \n",
       "1                0.001              20                1.0                 50   \n",
       "2                  0.1              20                1.0                 50   \n",
       "3                  0.1              20                1.0                 50   \n",
       "4                0.001             100               sqrt                 50   \n",
       "5                0.001             100               sqrt                 50   \n",
       "6                  0.1             100               sqrt                 50   \n",
       "7                  0.1             100               sqrt                 50   \n",
       "8                0.001              70                1.0                 10   \n",
       "9                0.001              70                1.0                 10   \n",
       "10                 0.1              70                1.0                 10   \n",
       "11                 0.1              70                1.0                 10   \n",
       "12               0.001             100               sqrt                 10   \n",
       "13               0.001             100               sqrt                 10   \n",
       "14                 0.1             100               sqrt                 10   \n",
       "15                 0.1             100               sqrt                 10   \n",
       "\n",
       "   param_subsample                                             params  \\\n",
       "0              0.8  {'learning_rate': 0.001, 'max_depth': 20, 'max...   \n",
       "1              1.0  {'learning_rate': 0.001, 'max_depth': 20, 'max...   \n",
       "2              0.8  {'learning_rate': 0.1, 'max_depth': 20, 'max_f...   \n",
       "3              1.0  {'learning_rate': 0.1, 'max_depth': 20, 'max_f...   \n",
       "4              0.8  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "5              1.0  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "6              0.8  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "7              1.0  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "8              0.8  {'learning_rate': 0.001, 'max_depth': 70, 'max...   \n",
       "9              1.0  {'learning_rate': 0.001, 'max_depth': 70, 'max...   \n",
       "10             0.8  {'learning_rate': 0.1, 'max_depth': 70, 'max_f...   \n",
       "11             1.0  {'learning_rate': 0.1, 'max_depth': 70, 'max_f...   \n",
       "12             0.8  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "13             1.0  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "14             0.8  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "15             1.0  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0        -2316.155829       -2292.261900       -2249.587536     -2286.001755   \n",
       "1        -2315.840445       -2291.895284       -2249.760211     -2285.831980   \n",
       "2         -602.879907        -590.303962        -567.286072      -586.823314   \n",
       "3         -616.910621        -604.837185        -592.255086      -604.667631   \n",
       "4        -2320.359644       -2297.024085       -2253.553709     -2290.312479   \n",
       "5        -2319.231686       -2295.597175       -2252.595126     -2289.141329   \n",
       "6         -601.621072        -588.631223        -572.459033      -587.570443   \n",
       "7         -604.230360        -598.743866        -580.853467      -594.609231   \n",
       "8        -2456.093940       -2433.669172       -2388.440344     -2426.067819   \n",
       "9        -2456.027120       -2433.550866       -2388.447093     -2426.008359   \n",
       "10        -866.380545        -837.564872        -813.668724      -839.204713   \n",
       "11        -876.514064        -845.413807        -826.294196      -849.407356   \n",
       "12       -2457.280547       -2435.029909       -2389.777880     -2427.362779   \n",
       "13       -2457.102358       -2434.712817       -2389.420032     -2427.078402   \n",
       "14        -880.374256        -850.721003        -830.949707      -854.014989   \n",
       "15        -866.819729        -846.442768        -820.086015      -844.449504   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0        27.534542               10  \n",
       "1        27.315711                9  \n",
       "2        14.738079                1  \n",
       "3        10.066294                4  \n",
       "4        27.683238               12  \n",
       "5        27.584612               11  \n",
       "6        11.928958                2  \n",
       "7         9.981356                3  \n",
       "8        28.137611               14  \n",
       "9        28.100202               13  \n",
       "10       21.550728                5  \n",
       "11       20.695734                7  \n",
       "12       28.086072               16  \n",
       "13       28.153597               15  \n",
       "14       20.311479                8  \n",
       "15       19.130949                6  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 20, 'max_features': 1.0, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbt = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = np.floor(best_gbt.predict(X_train)).astype(int)\n",
    "test_y_pred = np.floor(best_gbt.predict(X_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 14.952137945652625\n",
      "train mae: 4.751572408432017\n",
      "train r2 score: 0.909240502953645\n"
     ]
    }
   ],
   "source": [
    "print(\"train rmse:\", root_mean_squared_error(Y_train, train_y_pred))\n",
    "print(\"train mae:\", mean_absolute_error(Y_train, train_y_pred))\n",
    "print(\"train r2 score:\", r2_score(Y_train, train_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse: 28.511713288921644\n",
      "test mae: 7.577101831472448\n",
      "test r2 score: 0.6515397997474961\n"
     ]
    }
   ],
   "source": [
    "print(\"test rmse:\", root_mean_squared_error(Y_test, test_y_pred))\n",
    "print(\"test mae:\", mean_absolute_error(Y_test, test_y_pred))\n",
    "print(\"test r2 score:\", r2_score(Y_test, test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_gbt, open(os.path.join(MODELS_FOLDER, \"tuned_gbt.pkl\"), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
