{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    root_mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    make_scorer,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"clean_data/train_wo_weather.csv\")\n",
    "test_df = pd.read_csv(\"clean_data/test_wo_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[[x for x in train_df.columns if x not in [\"On\", \"Off\"]]]\n",
    "Y_train = train_df[\"On\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[[x for x in test_df.columns if x not in [\"On\", \"Off\"]]]\n",
    "Y_test = test_df[\"On\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1        2325.3998            6.18m\n",
      "         2        2213.7135            6.00m\n",
      "         3        2122.8957            5.98m\n",
      "         4        2047.1944            5.90m\n",
      "         5        1983.3689            5.85m\n",
      "         6        1924.6332            5.82m\n",
      "         7        1875.0695            5.79m\n",
      "         8        1837.8375            5.73m\n",
      "         9        1800.9505            5.66m\n",
      "        10        1772.4494            5.60m\n",
      "        11        1745.0150            5.55m\n",
      "        12        1723.6290            5.47m\n",
      "        13        1695.1193            5.42m\n",
      "        14        1676.5471            5.36m\n",
      "        15        1659.8533            5.29m\n",
      "        16        1644.0544            5.24m\n",
      "        17        1631.1337            5.17m\n",
      "        18        1613.6291            5.11m\n",
      "        19        1602.9795            5.05m\n",
      "        20        1591.9675            4.98m\n",
      "        21        1582.3163            4.91m\n",
      "        22        1574.4110            4.85m\n",
      "        23        1565.6227            4.78m\n",
      "        24        1559.6280            4.72m\n",
      "        25        1551.9230            4.65m\n",
      "        26        1546.8477            4.58m\n",
      "        27        1540.0032            4.52m\n",
      "        28        1534.8456            4.45m\n",
      "        29        1528.9884            4.39m\n",
      "        30        1525.2045            4.33m\n",
      "        31        1520.1441            4.27m\n",
      "        32        1510.8066            4.20m\n",
      "        33        1501.9546            4.14m\n",
      "        34        1497.1818            4.08m\n",
      "        35        1493.0873            4.02m\n",
      "        36        1490.3841            3.96m\n",
      "        37        1486.7222            3.89m\n",
      "        38        1482.8176            3.83m\n",
      "        39        1476.0879            3.76m\n",
      "        40        1472.4038            3.70m\n",
      "        41        1470.5366            3.64m\n",
      "        42        1467.3759            3.58m\n",
      "        43        1464.0242            3.52m\n",
      "        44        1456.8875            3.45m\n",
      "        45        1454.1589            3.38m\n",
      "        46        1452.4440            3.32m\n",
      "        47        1449.8694            3.26m\n",
      "        48        1447.1297            3.20m\n",
      "        49        1444.4590            3.14m\n",
      "        50        1438.5472            3.08m\n",
      "        51        1432.4712            3.01m\n",
      "        52        1429.9621            2.95m\n",
      "        53        1427.5926            2.89m\n",
      "        54        1421.5721            2.83m\n",
      "        55        1417.9783            2.77m\n",
      "        56        1410.0244            2.71m\n",
      "        57        1407.5735            2.65m\n",
      "        58        1406.4160            2.59m\n",
      "        59        1399.9090            2.53m\n",
      "        60        1395.0735            2.47m\n",
      "        61        1390.6210            2.41m\n",
      "        62        1389.5830            2.35m\n",
      "        63        1386.4309            2.29m\n",
      "        64        1381.8237            2.22m\n",
      "        65        1380.5100            2.16m\n",
      "        66        1375.3223            2.10m\n",
      "        67        1373.7093            2.04m\n",
      "        68        1372.8830            1.98m\n",
      "        69        1368.5838            1.92m\n",
      "        70        1362.7401            1.85m\n",
      "        71        1356.8935            1.79m\n",
      "        72        1356.1203            1.73m\n",
      "        73        1354.3833            1.67m\n",
      "        74        1351.9781            1.61m\n",
      "        75        1351.2723            1.55m\n",
      "        76        1346.0609            1.48m\n",
      "        77        1345.4109            1.42m\n",
      "        78        1342.8167            1.36m\n",
      "        79        1337.8226            1.30m\n",
      "        80        1334.3226            1.24m\n",
      "        81        1332.2686            1.18m\n",
      "        82        1330.9804            1.11m\n",
      "        83        1328.8124            1.05m\n",
      "        84        1325.4938           59.43s\n",
      "        85        1324.3047           55.73s\n",
      "        86        1322.8138           52.04s\n",
      "        87        1319.6434           48.30s\n",
      "        88        1319.0844           44.62s\n",
      "        89        1318.1878           40.88s\n",
      "        90        1317.3687           37.16s\n",
      "        91        1314.8197           33.42s\n",
      "        92        1313.4046           29.71s\n",
      "        93        1309.0442           26.00s\n",
      "        94        1306.9764           22.29s\n",
      "        95        1306.3506           18.57s\n",
      "        96        1302.0049           14.86s\n",
      "        97        1301.2300           11.15s\n",
      "        98        1299.8662            7.43s\n",
      "        99        1299.0711            3.72s\n",
      "       100        1296.0301            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(random_state=42, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(random_state=42, verbose=2)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(random_state=42, verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state = 42, verbose=2)\n",
    "gbr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_gbr = np.floor(gbr.predict(X_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_gbr = float(format(np.sqrt(mean_squared_error(Y_test, Y_pred_gbr)), '.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_FOLDER = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gbr, open(os.path.join(MODELS_FOLDER, \"base_gbt_wo_weather.pkl\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse: 32.33998435494458, mae: 12.464130113257495, r2: 0.5516820141097065\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(Y_test, Y_pred_gbr)\n",
    "rmse = root_mean_squared_error(Y_test, Y_pred_gbr)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_gbr)\n",
    "print(f\"test rmse: {rmse}, mae: {mae}, r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 36.00587159176965, mae: 12.98803066279469, r2: 0.47370148216725916\n"
     ]
    }
   ],
   "source": [
    "Y_pred_gbr = np.floor(gbr.predict(X_train)).astype(int)\n",
    "r2 = r2_score(Y_train, Y_pred_gbr)\n",
    "rmse = root_mean_squared_error(Y_train, Y_pred_gbr)\n",
    "mae = mean_absolute_error(Y_train, Y_pred_gbr)\n",
    "print(f\"train rmse: {rmse}, mae: {mae}, r2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gbt = GradientBoostingRegressor(\n",
    "    random_state=42,\n",
    "    loss=\"squared_error\",\n",
    "    criterion=\"friedman_mse\",\n",
    "    min_samples_split=14,\n",
    "    min_samples_leaf=7,\n",
    "    verbose=2,\n",
    ")\n",
    "param_grid = [\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [50],\n",
    "        \"max_depth\": [20],\n",
    "        \"max_features\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [50],\n",
    "        \"max_depth\": [100],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [10],\n",
    "        \"max_depth\": [70],\n",
    "        \"max_features\": [1.0],\n",
    "    },\n",
    "    {\n",
    "        \"learning_rate\": [0.001, 0.1],\n",
    "        \"subsample\": [0.8, 1.0],\n",
    "        \"n_estimators\": [10],\n",
    "        \"max_depth\": [100],\n",
    "        \"max_features\": [\"sqrt\"],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "grid_search = GridSearchCV(base_gbt, param_grid, scoring=scorer, n_jobs=-1, verbose=2, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time       Iter       Train Loss      OOB Improve   Remaining Time \n",
      "\n",
      "         1        2080.7238         339.5176           13.25m\n",
      "         1        2446.1562           3.5803           13.37m\n",
      "         1        2099.8396         348.3623           13.35m\n",
      "         1        2088.7452         340.4439           13.42m\n",
      "         1        2467.8591           3.6767           13.42m\n",
      "         1        2455.5513           3.5918           13.51m\n",
      "         1        2444.4402           16.21m\n",
      "         1        2455.4285           16.25m\n",
      "         1        2079.4457           16.31m\n",
      "         1        2478.3101           16.61m\n",
      "         2        2452.8739          46.0198           13.06m\n",
      "         2        1793.1351         332.1589           13.12m\n",
      "         2        1799.1080         323.0071           13.19m\n",
      "         2        2459.9040          36.5525           13.22m\n",
      "         2        1811.2955         341.3363           13.20m\n",
      "         2        2475.1378          48.4369           13.25m\n",
      "         2        2440.5670           15.73m\n",
      "         2        1780.4280           15.92m\n",
      "         2        2451.5537           15.96m\n",
      "         2        2474.4084           16.07m\n",
      "         3        2455.4045          29.3220           12.82m\n",
      "         3        1561.5692         258.4388           12.82m\n",
      "         3        1554.8064         259.9278           12.82m\n",
      "         3        2458.2186          12.4220           12.89m\n",
      "         3        1563.7879         228.6579           12.96m\n",
      "         3        2467.6347         -10.7685           12.98m\n",
      "         3        2436.7018           15.37m\n",
      "         3        1538.0055           15.53m\n",
      "         3        2470.5143           15.56m\n",
      "         3        2447.6867           15.60m\n",
      "         4        1347.3139         132.1078           12.58m\n",
      "         4        2431.7729         -75.4084           12.59m\n",
      "         4        1346.7103         149.5136           12.59m\n",
      "         4        2429.1342         -97.1984           12.72m\n",
      "         4        1363.3488         193.2420           12.72m\n",
      "         4        2453.6137         -36.7896           12.76m\n",
      "         4        2432.8441           15.00m\n",
      "         4        1340.7790           15.16m\n",
      "         4        2466.6280           15.17m\n",
      "         4        2443.8276           15.28m\n",
      "         5        1183.4753         147.1793           12.26m\n",
      "         5        2423.7067         -13.1685           12.34m\n",
      "         5        1188.8048         168.3330           12.33m\n",
      "         5        1213.4534         213.6812           12.39m\n",
      "         5        2474.7571         103.8528           12.45m\n",
      "         5        2429.2784          19.6567           12.47m\n",
      "         5        2428.9941           14.68m\n",
      "         6        1061.2704         167.0504           11.97m\n",
      "         6        1067.6693         170.5826           12.00m\n",
      "         5        2462.7496           14.75m\n",
      "         5        1180.3131           14.76m\n",
      "         6        2438.5665          78.5027           12.05m\n",
      "         6        1073.6963          96.7833           12.07m\n",
      "         5        2439.9762           14.85m\n",
      "         6        2459.4045         -42.3009           12.15m\n",
      "         6        2443.1299          74.3990           12.16m\n",
      "         7         950.0255          61.7483           11.70m\n",
      "         7         951.2387          90.8996           11.71m\n",
      "         7        2416.0241         -71.2255           11.73m\n",
      "         7         969.1224         121.5512           11.77m\n",
      "         7        2454.1311          -1.8976           11.83m\n",
      "         7        2414.2378         -96.6202           11.87m\n",
      "         6        2425.1518           14.36m\n",
      "         6        2458.8788           14.40m\n",
      "         6        1049.7393           14.46m\n",
      "         6        2436.1324           14.55m\n",
      "         8         873.8431         135.4566           11.40m\n",
      "         8         863.6986          86.7499           11.41m\n",
      "         8        2425.9769          58.7794           11.45m\n",
      "         8         872.1657          52.9350           11.50m\n",
      "         8        2443.8808         -21.9151           11.54m\n",
      "         8        2434.2158          98.8975           11.57m\n",
      "         7        2421.3172           14.03m\n",
      "         7        2455.0159           14.09m\n",
      "         7         943.3843           14.14m\n",
      "         7        2432.2963           14.19m\n",
      "         9         795.9428          46.4032           11.11m\n",
      "         9         790.1652          64.6887           11.12m\n",
      "         9        2419.4164          -7.3082           11.16m\n",
      "         9         812.4131         123.6918           11.17m\n",
      "         9        2465.8037         106.7647           11.22m\n",
      "         9        2424.8460         -18.5878           11.26m\n",
      "         8        2417.4906           13.67m\n",
      "         8        2451.1596           13.76m\n",
      "         8         856.5411           13.80m\n",
      "         8        2428.4682           13.85m\n",
      "        10         731.4028          36.7243           10.82m\n",
      "        10         721.3439          14.6042           10.84m\n",
      "        10        2395.1337         -78.3006           10.87m\n",
      "        10         748.6002          44.1151           10.87m\n",
      "        10        2410.4631         -38.7001           10.92m\n",
      "        10        2445.1802         -63.4340           10.93m\n",
      "         9        2413.6714           13.37m\n",
      "         9        2447.3112           13.45m\n",
      "         9         785.3156           13.49m\n",
      "        11         688.4264          71.5103           10.53m\n",
      "         9        2424.6473           13.53m\n",
      "        11         685.7498         101.5544           10.56m\n",
      "        11         699.7377          51.0046           10.59m\n",
      "        11        2413.2472          91.3476           10.63m\n",
      "        11        2416.3136          42.2862           10.65m\n",
      "        11        2440.2796          -0.5484           10.68m\n",
      "        12         644.0745          23.0550           10.26m\n",
      "        12         637.4732           5.9221           10.29m\n",
      "        12         664.4061          64.2820           10.31m\n",
      "        10        2409.8597           13.03m\n",
      "        12        2385.9029         -90.5903           10.35m\n",
      "        10        2443.4706           13.08m\n",
      "        12        2397.1416         -57.8962           10.38m\n",
      "        10         727.0671           13.14m\n",
      "        12        2446.7027          44.7412           10.41m\n",
      "        10        2420.8345           13.17m\n",
      "        13         618.8049          68.7235           10.01m\n",
      "        13         614.9769          74.4198           10.04m\n",
      "        13         620.5179          -6.0988           10.07m\n",
      "        13        2408.7800         110.3080           10.11m\n",
      "        13        2416.4842          96.2246           10.14m\n",
      "        13        2423.5870         -73.5783           10.15m\n",
      "        11        2406.0557           12.73m\n",
      "        11        2439.6375           12.77m\n",
      "        11         679.2223           12.82m\n",
      "        11        2417.0293           12.86m\n",
      "        14         584.7510           2.2720            9.74m\n",
      "        14         578.8202          -5.6603            9.76m\n",
      "        14         594.2376          35.3581            9.78m\n",
      "        14        2383.1497         -83.7634            9.83m\n",
      "        14        2388.7540         -92.2089            9.86m\n",
      "        14        2425.7270          27.3757            9.87m\n",
      "        12        2402.2593           12.37m\n",
      "        12        2435.8120           12.41m\n",
      "        12         639.6416           12.47m\n",
      "        12        2413.2317           12.51m\n",
      "        15         569.2139          55.5149            9.46m\n",
      "        15         566.4465          66.8360            9.48m\n",
      "        15         577.8625          54.6012            9.51m\n",
      "        15        2408.6452         120.6913            9.55m\n",
      "        15        2414.1071         120.1560            9.57m\n",
      "        15        2438.5962          70.3999            9.61m\n",
      "        13        2398.4706           12.03m\n",
      "        13        2431.9942           12.08m\n",
      "        13         607.1235           12.11m\n",
      "        13        2409.4416           12.17m\n",
      "        16         544.4810           0.4373            9.17m\n",
      "        16         543.4214           7.3920            9.19m\n",
      "        16         548.8753         -17.3089            9.21m\n",
      "        16        2395.9446         -32.1357            9.26m\n",
      "        16        2401.9850         -29.7923            9.27m\n",
      "        16        2416.6300         -69.1194            9.32m\n",
      "        14        2394.6896           11.70m\n",
      "        14        2428.1840           11.74m\n",
      "        14         580.3024           11.79m\n",
      "        17         524.0152           5.4386            8.91m\n",
      "        17         533.2351          38.2648            8.92m\n",
      "        14        2405.6590           11.83m\n",
      "        17         532.7079          20.2112            8.94m\n",
      "        17        2389.9932          -5.1630            8.98m\n",
      "        17        2407.1748          39.4499            9.00m\n",
      "        17        2431.1252          76.8057            9.04m\n",
      "        18         517.5767          44.8215            8.65m\n",
      "        15        2390.9160           11.36m\n",
      "        18         519.0266          14.7875            8.66m\n",
      "        18         523.5542          32.6772            8.67m\n",
      "        15        2424.3815           11.42m\n",
      "        18        2398.0334          50.7348            8.70m\n",
      "        18        2403.1050           2.3482            8.72m\n",
      "        15         558.0142           11.46m\n",
      "        15        2401.8837           11.48m\n",
      "        18        2417.0496         -37.6693            8.77m\n",
      "        19         501.2608          -2.4439            8.39m\n",
      "        19         508.3556          18.9462            8.39m\n",
      "        19         509.4768           8.4379            8.40m\n",
      "        19        2392.6958          -2.7496            8.44m\n",
      "        19        2393.4297         -20.1378            8.44m\n",
      "        16        2387.1500           11.03m\n",
      "        19        2417.2555          19.5821            8.49m\n",
      "        16        2420.5865           11.09m\n",
      "        16         539.4505           11.15m\n",
      "        16        2398.1164           11.17m\n",
      "        20         482.7461         -23.3403            8.13m\n",
      "        20         491.3438         -13.9728            8.13m\n",
      "        20         490.2652         -23.2617            8.13m\n",
      "        20        2355.5134        -130.2569            8.17m\n",
      "        20        2387.5362          -5.0157            8.17m\n",
      "        20        2387.4672        -100.4649            8.22m\n",
      "        17        2383.3916           10.69m\n",
      "        17        2416.7993           10.78m\n",
      "        17         523.1031           10.82m\n",
      "        17        2394.3564           10.83m\n",
      "        21         476.0421          20.1988            7.85m\n",
      "        21         483.3678          15.3479            7.86m\n",
      "        21         490.4831          49.3996            7.87m\n",
      "        21        2380.6300          -9.1656            7.90m\n",
      "        21        2363.3316          49.7359            7.90m\n",
      "        21        2410.6589         111.4661            7.94m\n",
      "        18        2379.6407           10.37m\n",
      "        18        2413.0195           10.44m\n",
      "        18         509.8116           10.48m\n",
      "        18        2390.6040           10.50m\n",
      "        22         467.4103           6.7801            7.57m\n",
      "        22         467.6602         -23.2515            7.58m\n",
      "        22         480.8812           8.6883            7.60m\n",
      "        22        2364.0107         -48.0415            7.62m\n",
      "        22        2361.3003          10.2772            7.63m\n",
      "        22        2416.1907          40.8813            7.67m\n",
      "        19        2375.8972           10.06m\n",
      "        19        2409.2472           10.13m\n",
      "        23         461.6168          13.1686            7.32m\n",
      "        19         498.2062           10.17m\n",
      "        19        2386.8590           10.19m\n",
      "        23         471.7899           0.1247            7.34m\n",
      "        23         469.4361          44.6552            7.34m\n",
      "        23        2378.1425          74.9676            7.35m\n",
      "        23        2372.7501          64.2654            7.37m\n",
      "        23        2393.1699         -73.5200            7.41m\n",
      "        20        2372.1613            9.74m\n",
      "        24         459.2444          21.8845            7.06m\n",
      "        24         462.5910          -1.0118            7.08m\n",
      "        24        2380.2292          26.7393            7.08m\n",
      "        24         466.8434          20.8065            7.08m\n",
      "        20        2405.4826            9.81m\n",
      "        24        2364.3589         -15.1717            7.10m\n",
      "        20         488.5557            9.87m\n",
      "        20        2383.1210            9.87m\n",
      "        24        2400.7813          49.0000            7.14m\n",
      "        25         445.5094         -27.5078            6.81m\n",
      "        25        2359.7442         -63.6308            6.82m\n",
      "        25         451.8224         -29.5030            6.82m\n",
      "        25        2333.8330        -103.8131            6.82m\n",
      "        21        2368.4327            9.42m\n",
      "        25         462.7229          27.6605            6.83m\n",
      "        25        2406.8180          42.6523            6.88m\n",
      "        21        2401.7253            9.50m\n",
      "        21        2379.3901            9.55m\n",
      "        21         479.9765            9.56m\n",
      "        26        2343.0375          55.0612            6.55m\n",
      "        26        2363.8478          34.7531            6.56m\n",
      "        26         442.8614          16.5566            6.56m\n",
      "        26         449.5625          16.5088            6.56m\n",
      "        26         454.1102          -9.7996            6.57m\n",
      "        22        2364.7117            9.11m\n",
      "        26        2381.0219         -84.7262            6.61m\n",
      "        22        2397.9757            9.19m\n",
      "        22        2375.6670            9.24m\n",
      "        22         472.3675            9.24m\n",
      "        27        2351.3610         -31.6926            6.28m\n",
      "        27        2348.2029          38.9429            6.28m\n",
      "        27         441.3485          -9.5839            6.30m\n",
      "        27         435.6095          -5.4400            6.30m\n",
      "        27         442.8450         -19.1879            6.30m\n",
      "        27        2365.0074         -45.6841            6.34m\n",
      "        23        2360.9977            8.79m\n",
      "        23        2394.2335            8.87m\n",
      "        23        2371.9511            8.91m\n",
      "        23         465.7526            8.93m\n",
      "        28        2364.2073          82.2157            6.01m\n",
      "        28        2356.8572          40.1947            6.01m\n",
      "        28         442.9221          29.7651            6.04m\n",
      "        28         439.3812           9.0984            6.04m\n",
      "        28         440.7068          43.9756            6.04m\n",
      "        28        2385.3525          99.8485            6.07m\n",
      "        24        2357.2914            8.46m\n",
      "        24        2390.4985            8.56m\n",
      "        24        2368.2426            8.58m\n",
      "        29        2346.1318         -24.6887            5.74m\n",
      "        29        2330.2736        -117.6087            5.74m\n",
      "        24         460.1322            8.61m\n",
      "        29         437.8048           0.5533            5.77m\n",
      "        29         441.0335          25.2461            5.78m\n",
      "        29         429.3144         -24.0108            5.78m\n",
      "        29        2359.8857         -83.6191            5.79m\n",
      "        25        2353.5921            8.13m\n",
      "        30        2344.3899          74.5287            5.47m\n",
      "        30        2356.0560          57.8460            5.47m\n",
      "        25        2386.7712            8.24m\n",
      "        30         435.7587          16.7053            5.50m\n",
      "        25        2364.5411            8.26m\n",
      "        30        2369.8035          57.9959            5.52m\n",
      "        30         429.6530          21.1860            5.52m\n",
      "        30         437.7947           6.9048            5.53m\n",
      "        25         455.3803            8.29m\n",
      "        26        2349.9005            7.82m\n",
      "        31        2348.9465          36.3270            5.20m\n",
      "        31        2347.1582         -17.4479            5.20m\n",
      "        31         425.5015         -18.8604            5.24m\n",
      "        31        2361.9505         -13.1631            5.25m\n",
      "        26        2383.0513            7.91m\n",
      "        31         431.5129          24.3455            5.26m\n",
      "        26        2360.8487            7.93m\n",
      "        31         433.8166           7.5392            5.27m\n",
      "        26         451.0960            7.98m\n",
      "        32        2333.5058         -43.6767            4.92m\n",
      "        32        2342.7015           0.2803            4.92m\n",
      "        27        2346.2159            7.50m\n",
      "        32         422.5237           5.6828            4.97m\n",
      "        32        2362.7889          21.5559            4.97m\n",
      "        32         420.7491         -24.9682            4.99m\n",
      "        32         426.7234         -10.8674            5.00m\n",
      "        27        2379.3389            7.59m\n",
      "        27        2357.1618            7.60m\n",
      "        27         447.0343            7.68m\n",
      "        33        2339.4143           4.9331            4.65m\n",
      "        33        2332.4368          13.8008            4.65m\n",
      "        33        2374.6971          65.8657            4.69m\n",
      "        33         421.0902          13.1944            4.70m\n",
      "        28        2342.5394            7.17m\n",
      "        33         417.7874           3.6767            4.72m\n",
      "        33         426.0426          19.4467            4.73m\n",
      "        28        2375.6337            7.25m\n",
      "        28        2353.4827            7.27m\n",
      "        34        2320.7231         -56.7907            4.38m\n",
      "        34        2316.0229         -47.6899            4.38m\n",
      "        28         443.5796            7.35m\n",
      "        34        2350.2781         -79.5366            4.42m\n",
      "        34         413.6073         -12.3572            4.43m\n",
      "        34         414.1453           1.8676            4.44m\n",
      "        29        2338.8694            6.84m\n",
      "        34         420.4866          -7.0544            4.45m\n",
      "        29        2371.9364            6.92m\n",
      "        29        2349.8108            6.94m\n",
      "        35        2320.1010          15.5304            4.11m\n",
      "        35        2323.9565          49.6933            4.11m\n",
      "        35        2371.0324         101.1474            4.15m\n",
      "        35         409.4065          -0.5093            4.15m\n",
      "        29         439.8786            7.03m\n",
      "        35         421.1953          20.7678            4.17m\n",
      "        35         412.0694           6.2508            4.17m\n",
      "        30        2335.2072            6.51m\n",
      "        36        2323.3461          30.9547            3.83m\n",
      "        36        2304.7894         -58.7202            3.84m\n",
      "        30        2368.2461            6.59m\n",
      "        30        2346.1466            6.61m\n",
      "        36        2344.2144         -89.1639            3.87m\n",
      "        36         407.1689           7.8556            3.88m\n",
      "        36         406.4695          -7.0776            3.90m\n",
      "        36         411.9500         -19.7159            3.90m\n",
      "        30         436.7045            6.70m\n",
      "        31        2331.5523            6.19m\n",
      "        37        2318.9880           0.5015            3.56m\n",
      "        37        2296.3933         -15.7916            3.56m\n",
      "        31        2364.5630            6.26m\n",
      "        37        2348.8465          36.5481            3.59m\n",
      "        31        2342.4892            6.27m\n",
      "        37         407.2945          16.5656            3.60m\n",
      "        37         404.6374           6.5196            3.62m\n",
      "        37         412.5592          16.4293            3.63m\n",
      "        38        2331.1238          66.3995            3.28m\n",
      "        38        2309.6169          70.7683            3.29m\n",
      "        31         433.6979            6.38m\n",
      "        32        2327.9048            5.87m\n",
      "        38        2355.5339          44.7972            3.31m\n",
      "        32        2360.8880            5.93m\n",
      "        38         406.5685          13.3214            3.33m\n",
      "        32        2338.8393            5.94m\n",
      "        38         405.1104          16.7989            3.35m\n",
      "        38         412.1201          11.6529            3.35m\n",
      "        39        2313.7427         -51.7065            3.01m\n",
      "        39        2304.7107          -1.7712            3.01m\n",
      "        33        2324.2640            5.54m\n",
      "        32         430.9907            6.05m\n",
      "        39        2340.1955         -43.2980            3.04m\n",
      "        39         402.4172          -2.2422            3.05m\n",
      "        33        2357.2199            5.60m\n",
      "        39         400.2901          -6.9027            3.07m\n",
      "        33        2335.1973            5.61m\n",
      "        39         410.2550           6.2365            3.07m\n",
      "        40        2276.8525         -93.6487            2.74m\n",
      "        40        2309.2731          -0.0164            2.74m\n",
      "        40        2325.0541         -42.6441            2.76m\n",
      "        34        2320.6311            5.22m\n",
      "        33         428.0581            5.72m\n",
      "        40         397.4218          -7.9604            2.78m\n",
      "        40         391.4734         -20.0245            2.79m\n",
      "        40         401.0105         -21.3920            2.80m\n",
      "        34        2353.5591            5.27m\n",
      "        34        2331.5627            5.27m\n",
      "        41        2302.3931          -9.8108            2.46m\n",
      "        41        2288.7505          65.3280            2.46m\n",
      "        41        2322.9769           9.6484            2.48m\n",
      "        41         393.8469          -2.7853            2.50m\n",
      "        35        2317.0054            4.89m\n",
      "        41         387.7571          -2.8639            2.51m\n",
      "        34         424.9140            5.39m\n",
      "        41         400.0298           9.3417            2.52m\n",
      "        42        2285.7949           5.8993            2.19m\n",
      "        42        2296.0931          -7.4648            2.19m\n",
      "        35        2349.9059            4.94m\n",
      "        35        2327.9350            4.95m\n",
      "        42        2329.4268          43.7318            2.20m\n",
      "        42         390.7129           3.9963            2.23m\n",
      "        42         389.5014          20.6864            2.23m\n",
      "        36        2313.3862            4.56m\n",
      "        43        2301.3283          79.8771            1.91m\n",
      "        43        2315.1630          94.0253            1.92m\n",
      "        42         398.3725           6.3539            2.24m\n",
      "        35         422.2484            5.06m\n",
      "        43        2309.5129         -61.8215            1.93m\n",
      "        36        2346.2603            4.61m\n",
      "        36        2324.3146            4.62m\n",
      "        43         391.0560          13.7583            1.95m\n",
      "        44        2276.8507         -80.2595            1.64m\n",
      "        43         384.3065          -6.3352            1.96m\n",
      "        44        2296.4508         -57.1992            1.64m\n",
      "        37        2309.7743            4.23m\n",
      "        43         393.6983          -6.2059            1.96m\n",
      "        44        2316.8754          47.2629            1.65m\n",
      "        36         419.4934            4.73m\n",
      "        37        2342.6219            4.28m\n",
      "        37        2320.7006            4.29m\n",
      "        44         386.2541          -3.4718            1.68m\n",
      "        45        2288.5499          64.3971            1.37m\n",
      "        45        2281.5996         -41.8657            1.37m\n",
      "        44         382.0911           4.2172            1.68m\n",
      "        44         391.1146           1.8796            1.69m\n",
      "        38        2306.1697            3.91m\n",
      "        45        2311.4311          -4.0253            1.38m\n",
      "        38        2338.9914            3.95m\n",
      "        37         416.8580            4.40m\n",
      "        38        2317.0950            3.96m\n",
      "        46        2277.0349         -28.4650            1.09m\n",
      "        46        2310.6489         133.8089            1.10m\n",
      "        45         383.3755           0.5735            1.40m\n",
      "        45         386.9099          34.0399            1.40m\n",
      "        45         388.1395          -2.7614            1.41m\n",
      "        46        2308.3392           5.3546            1.10m\n",
      "        39        2302.5722            3.58m\n",
      "        39        2335.3672            3.62m\n",
      "        39        2313.4965            3.62m\n",
      "        47        2264.5157         -32.6142           49.23s\n",
      "        47        2287.6320         -74.5066           49.27s\n",
      "        38         414.7430            4.07m\n",
      "        46         384.2270          13.4459            1.12m\n",
      "        47        2300.3140         -14.3812           49.54s\n",
      "        46         376.9131         -31.9005            1.12m\n",
      "        46         390.6968          18.8904            1.13m\n",
      "        40        2298.9819            3.26m\n",
      "        48        2277.4308          69.1568           32.85s\n",
      "        48        2282.8041          -1.7843           32.86s\n",
      "        40        2331.7504            3.29m\n",
      "        40        2309.9053            3.29m\n",
      "        47         377.3853         -15.2648           50.56s\n",
      "        48        2303.4878          30.2786           33.02s\n",
      "        39         412.3970            3.73m\n",
      "        47         376.0240          10.9247           50.72s\n",
      "        47         382.2770         -22.2852           50.78s\n",
      "        41        2295.3992            2.93m\n",
      "        49        2276.9817          15.6766           16.42s\n",
      "        49        2290.8631          49.7701           16.43s\n",
      "        41        2328.1415            2.96m\n",
      "        49        2312.5294          53.8234           16.51s\n",
      "        48         376.4756           8.0479           33.75s\n",
      "        41        2306.3209            2.96m\n",
      "        48         378.7289          18.7430           33.90s\n",
      "        48         385.4142          21.9668           33.94s\n",
      "        40         410.0957            3.40m\n",
      "        42        2291.8238            2.61m\n",
      "        50        2260.3985         -48.9743            0.00s\n",
      "        50        2275.2645         -44.9529            0.00s\n",
      "        50        2312.3610          17.0002            0.00s\n",
      "        42        2324.5393            2.63m\n",
      "        49         377.2937          16.6576           16.89s\n",
      "        42        2302.7438            2.63m\n",
      "        49         383.6630           4.8036           16.96s\n",
      "        49         377.1809           8.5467           16.97s\n",
      "        41         407.4065            3.06m\n",
      "        43        2288.2555            2.28m\n",
      "        50         372.0087         -10.4231            0.00s\n",
      "        43        2320.9443            2.30m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=14.1min\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=14.1min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "        50         369.8063         -20.9111            0.00s\n",
      "        43        2299.1733            2.30m\n",
      "        50         383.6958           8.4245            0.00s\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=14.2min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        42         404.6213            2.72m\n",
      "        44        2284.6935            1.95m\n",
      "         1        2446.1475           3.5602            7.47m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=14.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        44        2317.3560            1.96m\n",
      "         1        2090.2883           15.23m\n",
      "         1        2110.6345           15.75m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=14.5min\n",
      "        44        2295.6106            1.97m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=0.8; total time=14.5min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "      Iter       Train Loss   Remaining Time \n",
      "         2        2452.8888          46.0231            7.51m\n",
      "         1        2455.5306           3.5977            8.23m\n",
      "        45        2281.1391            1.62m\n",
      "         1        2467.8601           3.6929            8.53m\n",
      "        43         401.4388            2.38m\n",
      "         3        2455.4768          29.2666            7.59m\n",
      "         1        2444.4208            9.41m\n",
      "        45        2313.7761            1.64m\n",
      "         2        2459.8813          36.5628            8.00m\n",
      "         2        1790.9833           14.94m\n",
      "         2        1808.9557           15.49m\n",
      "        45        2292.0547            1.64m\n",
      "         2        2475.1592          48.4094            8.21m\n",
      "         4        2431.8550         -75.4120            7.36m\n",
      "         2        2440.5716            9.24m\n",
      "         3        2458.2373          12.3725            7.92m\n",
      "        46        2277.5920            1.30m\n",
      "         3        2467.6376         -10.7431            8.04m\n",
      "         5        2423.7871         -13.1971            7.22m\n",
      "        44         399.7081            2.04m\n",
      "        46        2310.2026            1.31m\n",
      "         3        1548.3820           14.58m\n",
      "         3        2436.6977            9.20m\n",
      "         4        2429.1529         -97.1861            7.68m\n",
      "         3        1563.5908           15.04m\n",
      "        46        2288.5063            1.31m\n",
      "         6        2438.6351          78.4824            7.07m\n",
      "         4        2453.6522         -36.8402            7.83m\n",
      "        47        2274.0517           58.27s\n",
      "         5        2429.3095          19.6475            7.46m\n",
      "         4        2432.8827            9.01m\n",
      "         5        2474.8210         103.7498            7.60m\n",
      "         7        2416.1034         -71.2471            6.97m\n",
      "        45         397.7952            1.70m\n",
      "        47        2306.6362           58.75s\n",
      "         4        1350.8275           14.27m\n",
      "         6        2443.1427          74.3884            7.27m\n",
      "         4        1364.3224           14.65m\n",
      "        47        2284.9645           58.97s\n",
      "         5        2429.0861            8.71m\n",
      "         8        2426.0859          58.9265            6.79m\n",
      "         6        2459.5123         -42.2068            7.41m\n",
      "        48        2270.5184           38.81s\n",
      "         7        2414.2015         -96.5920            7.08m\n",
      "         7        2454.2412          -1.9431            7.15m\n",
      "         9        2419.5491          -7.4180            6.64m\n",
      "         6        2425.2442            8.57m\n",
      "        48        2303.0766           39.13s\n",
      "         5        1190.2062           14.01m\n",
      "        46         393.8706            1.36m\n",
      "         8        2434.2142          98.9136            6.90m\n",
      "         5        1202.0906           14.35m\n",
      "        48        2281.4304           39.28s\n",
      "         8        2443.9538         -21.9258            6.96m\n",
      "        10        2395.2742         -78.3792            6.47m\n",
      "         7        2421.4493            8.39m\n",
      "        49        2266.9922           19.39s\n",
      "         9        2424.8218         -18.5862            6.72m\n",
      "         9        2465.9467         106.7976            6.78m\n",
      "        11        2413.4376          91.3980            6.30m\n",
      "        49        2299.5251           19.56s\n",
      "         6        1059.3325           13.74m\n",
      "         6        1070.2661           14.03m\n",
      "        10        2410.4258         -38.7082            6.56m\n",
      "        49        2277.9024           19.63s\n",
      "         8        2417.6028            8.26m\n",
      "        47         391.1634            1.02m\n",
      "        10        2445.3478         -63.4645            6.61m\n",
      "        12        2386.0666         -90.6872            6.17m\n",
      "        50        2263.4735            0.00s\n",
      "        11        2416.3220          42.2631            6.40m\n",
      "         9        2413.7674            8.07m\n",
      "        11        2440.4456          -0.6139            6.41m\n",
      "        50        2295.9801            0.00s\n",
      "        13        2409.0082         110.3344            6.04m\n",
      "         7         952.4229           13.40m\n",
      "         7         962.4739           13.63m\n",
      "        50        2274.3810            0.00s\n",
      "        12        2397.1388         -57.8654            6.18m\n",
      "        48         388.4272           40.92s\n",
      "        12        2446.8715          44.7613            6.18m\n",
      "        10        2409.9588            7.77m\n",
      "        14        2383.4237         -83.8131            5.83m\n",
      "        13        2416.4902          96.2190            6.02m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=16.6min\n",
      "        13        2423.8131         -73.7638            6.00m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        15        2408.9307         120.7668            5.65m\n",
      "         8         865.2700           13.00m\n",
      "        11        2406.1530            7.58m\n",
      "         8         874.2916           13.26m\n",
      "        14        2388.7747         -92.1876            5.84m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=16.7min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        49         386.6227           20.46s\n",
      "        14        2425.9496          27.4515            5.83m\n",
      "        16        2396.2476         -32.1576            5.48m\n",
      "         1        2455.4272            9.31m\n",
      "[CV] END learning_rate=0.001, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=16.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        12        2402.3853            7.38m\n",
      "        15        2414.1935         120.2369            5.68m\n",
      "         1        2478.2792            9.35m\n",
      "        15        2438.8335          70.3997            5.66m\n",
      "         9         794.1150           12.70m\n",
      "        17        2390.3337          -5.1455            5.32m\n",
      "         1        2079.9004         337.6045            7.74m\n",
      "         2        2451.6087            9.28m\n",
      "         9         802.1927           12.92m\n",
      "        16        2402.0718         -29.9010            5.50m\n",
      "        13        2398.6290            7.18m\n",
      "        16        2416.8492         -69.0555            5.51m\n",
      "         2        2474.5050            8.98m\n",
      "        18        2398.3552          50.5743            5.15m\n",
      "        50         384.3380            0.00s\n",
      "         2        1792.0589         333.1727            7.46m\n",
      "        17        2407.2877          39.3189            5.31m\n",
      "         3        2447.7062            8.98m\n",
      "        14        2394.8411            6.98m\n",
      "        10         735.3291           12.32m\n",
      "        17        2431.3778          76.9029            5.33m\n",
      "        19        2393.1074          -2.6847            4.96m\n",
      "         3        1557.3536         256.8837            7.33m\n",
      "         3        2470.5720            8.73m\n",
      "        10         743.1084           12.54m\n",
      "        18        2403.2295           2.3430            5.14m\n",
      "         4        2443.8323            8.84m\n",
      "        18        2417.2487         -37.7030            5.14m\n",
      "        20        2355.8887        -130.4318            4.79m\n",
      "        15        2391.0452            6.78m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=17.4min\n",
      "         4        1350.4929         148.7885            7.07m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         4        2466.6763            8.50m\n",
      "        19        2393.5481         -20.1849            4.95m\n",
      "        11         687.3811           11.97m\n",
      "        19        2417.4333          19.5254            4.96m\n",
      "        21        2363.7371          49.5402            4.60m\n",
      "         5        2439.9873            8.53m\n",
      "         5        1187.2908         150.1191            6.87m\n",
      "         1        2086.7749         340.8753            7.43m\n",
      "        11         694.6234           12.17m\n",
      "        16        2387.2848            6.57m\n",
      "        20        2387.6424          -4.9288            4.78m\n",
      "         5        2462.7578            8.33m\n",
      "        20        2387.6654        -100.6107            4.78m\n",
      "        22        2361.7384          10.4957            4.43m\n",
      "         6        1062.5839         165.5808            6.70m\n",
      "         2        1797.3942         322.6655            7.34m\n",
      "         6        2436.1292            8.31m\n",
      "        21        2380.6956          -9.2244            4.60m\n",
      "        17        2383.5472            6.39m\n",
      "        12         647.7529           11.64m\n",
      "        23        2373.1628          64.1833            4.26m\n",
      "        21        2410.8835         111.5633            4.62m\n",
      "         6        2458.9051            8.18m\n",
      "         7         950.5911          89.7893            6.57m\n",
      "         3        1559.5971         260.3183            7.22m\n",
      "        12         654.3402           11.82m\n",
      "        22        2364.0784         -47.9531            4.43m\n",
      "         7        2432.2712            8.15m\n",
      "        18        2379.8122            6.17m\n",
      "        24        2364.7940         -15.2545            4.09m\n",
      "        22        2416.4661          40.8849            4.44m\n",
      "         7        2455.1097            7.98m\n",
      "         4        1346.2350         133.1985            6.97m\n",
      "         8         863.7993          95.2186            6.44m\n",
      "        23        2378.2827          74.9910            4.26m\n",
      "         8        2428.4317            7.90m\n",
      "        13         614.8942           11.31m\n",
      "        25        2334.2704        -103.8433            3.93m\n",
      "        23        2393.4755         -73.6265            4.28m\n",
      "        19        2376.0450            5.97m\n",
      "         5        1185.2628         168.6082            6.78m\n",
      "         9         789.0292          62.4035            6.31m\n",
      "        13         621.1319           11.50m\n",
      "        24        2380.2982          26.5833            4.09m\n",
      "         8        2451.2307            7.81m\n",
      "        26        2343.4687          54.9175            3.77m\n",
      "         9        2424.6182            7.69m\n",
      "        24        2401.1473          49.2762            4.12m\n",
      "         6        1064.2292         171.6890            6.69m\n",
      "        20        2372.3283            5.76m\n",
      "        10         717.6830          12.1592            6.16m\n",
      "        25        2359.7697         -63.6518            3.93m\n",
      "         9        2447.3441            7.60m\n",
      "        14         587.6480           10.97m\n",
      "        27        2348.6642          39.0627            3.61m\n",
      "        25        2407.1667          42.5821            3.95m\n",
      "        10        2420.8072            7.50m\n",
      "         7         942.9154          59.8402            6.56m\n",
      "        11         681.4000         106.8688            5.98m\n",
      "        14         593.6601           11.17m\n",
      "        26        2363.8224          34.6774            3.77m\n",
      "        21        2368.5983            5.55m\n",
      "        10        2443.4888            7.39m\n",
      "        28        2364.7207          82.5172            3.45m\n",
      "        26        2381.3994         -84.9242            3.78m\n",
      "         8         867.3120         139.8881            6.40m\n",
      "        12         630.7121           3.2277            5.85m\n",
      "        27        2351.3333         -31.6439            3.61m\n",
      "        11        2416.9996            7.33m\n",
      "        22        2364.8670            5.35m\n",
      "        15         564.8271           10.63m\n",
      "        27        2365.3852         -45.8695            3.62m\n",
      "        29        2330.7487        -117.9736            3.29m\n",
      "        11        2439.6426            7.29m\n",
      "         9         787.5214          46.4199            6.25m\n",
      "        13         607.3595          77.4926            5.71m\n",
      "        15         570.8848           10.86m\n",
      "        28        2356.9026          40.4888            3.45m\n",
      "        12        2413.2031            7.11m\n",
      "        28        2385.7771         100.0145            3.45m\n",
      "        30        2344.9251          74.6960            3.12m\n",
      "        23        2361.1447            5.15m\n",
      "        10         722.7218          36.9872            6.12m\n",
      "        12        2435.8447            7.09m\n",
      "        14         572.1620          -5.0427            5.57m\n",
      "        29        2346.1538         -24.9397            3.29m\n",
      "        16         545.8887           10.32m\n",
      "        13        2409.4020            6.91m\n",
      "        29        2360.2884         -83.7645            3.29m\n",
      "        31        2349.4905          36.3333            2.96m\n",
      "        24        2357.4379            4.97m\n",
      "        11         678.3424          69.8646            5.96m\n",
      "        16         551.6558           10.53m\n",
      "        30        2356.1137          58.0051            3.13m\n",
      "        15         557.9758          65.3250            5.43m\n",
      "        13        2432.0020            6.91m\n",
      "        30        2370.3400          58.1621            3.14m\n",
      "        32        2334.1361         -43.8763            2.81m\n",
      "        14        2405.5887            6.74m\n",
      "        12         634.5578          26.8021            5.82m\n",
      "        31        2347.2856         -17.4495            2.97m\n",
      "        25        2353.7429            4.78m\n",
      "        16         536.1963          11.7796            5.27m\n",
      "        17         529.9906           10.02m\n",
      "        14        2428.1599            6.74m\n",
      "        33        2333.1701          14.1660            2.65m\n",
      "        31        2362.5218         -13.3316            2.98m\n",
      "        15        2401.7789            6.57m\n",
      "        13         610.1179          66.8291            5.70m\n",
      "        17         535.8163           10.22m\n",
      "        32        2342.8633           0.2278            2.81m\n",
      "        17         516.1981           3.0798            5.13m\n",
      "        26        2350.0790            4.59m\n",
      "        34        2316.7063         -48.0860            2.49m\n",
      "        32        2363.3257          21.5053            2.82m\n",
      "        15        2424.3246            6.58m\n",
      "        14         575.9843           3.1449            5.53m\n",
      "        33        2339.6148           4.9921            2.65m\n",
      "        18         509.1881          45.1177            4.96m\n",
      "        16        2397.9973            6.37m\n",
      "        18         516.3823            9.70m\n",
      "        33        2375.3134          66.1237            2.66m\n",
      "        35        2324.6737          49.8624            2.34m\n",
      "        27        2346.4176            4.40m\n",
      "        16        2420.5182            6.38m\n",
      "        18         521.8805            9.90m\n",
      "        15         560.3588          55.6212            5.38m\n",
      "        34        2320.9260         -56.9389            2.49m\n",
      "        19         494.0528          -1.1080            4.81m\n",
      "        17        2394.2121            6.22m\n",
      "        36        2305.4384         -59.0879            2.18m\n",
      "        34        2350.8497         -79.6945            2.50m\n",
      "        28        2342.7396            4.20m\n",
      "        16         536.4195           1.1440            5.23m\n",
      "        35        2320.3449          15.6073            2.34m\n",
      "        19         505.0631            9.39m\n",
      "        17        2416.6931            6.19m\n",
      "        20         474.9652         -23.5419            4.67m\n",
      "        35        2371.6271         101.1585            2.34m\n",
      "        37        2297.0787         -15.5974            2.02m\n",
      "        18        2390.4730            6.02m\n",
      "        29        2339.1106            4.00m\n",
      "        17         524.6321          38.1116            5.08m\n",
      "        19         509.8875            9.59m\n",
      "        36        2323.5896          30.7224            2.18m\n",
      "        21         468.6491          17.2997            4.51m\n",
      "        18        2412.8852            6.00m\n",
      "        36        2344.7133         -89.4622            2.19m\n",
      "        38        2310.3930          70.9235            1.87m\n",
      "        19        2386.7114            5.83m\n",
      "        18         510.9604          16.1761            4.93m\n",
      "        37        2319.2798           0.6805            2.03m\n",
      "        20         495.2160            9.08m\n",
      "        30        2335.4434            3.81m\n",
      "        22         459.0910           2.1928            4.36m\n",
      "        39        2305.4715          -1.8863            1.71m\n",
      "        37        2349.3272          36.6342            2.03m\n",
      "        19        2409.0960            5.83m\n",
      "        19         498.9874          13.4439            4.78m\n",
      "        20         499.5090            9.29m\n",
      "        38        2331.4405          66.4809            1.87m\n",
      "        20        2382.9672            5.64m\n",
      "        23         453.9859          16.6170            4.20m\n",
      "        31        2331.8504            3.61m\n",
      "        38        2356.0587          45.1172            1.87m\n",
      "        40        2277.5552         -93.8694            1.56m\n",
      "        20        2405.2948            5.64m\n",
      "        39        2313.9950         -51.9554            1.71m\n",
      "        20         481.2979         -15.0146            4.63m\n",
      "        21         486.6615            8.78m\n",
      "        24         451.4858          22.5459            4.04m\n",
      "        21        2379.2223            5.44m\n",
      "        41        2289.5423          65.5830            1.40m\n",
      "        39        2340.6007         -43.7667            1.72m\n",
      "        32        2328.2039            3.42m\n",
      "        21         490.4708            8.97m\n",
      "        40        2309.5057          -0.1252            1.56m\n",
      "        21         474.4732          18.0067            4.48m\n",
      "        21        2401.5570            5.45m\n",
      "        25         437.1869         -29.8139            3.88m\n",
      "        42        2286.6595           6.0189            1.24m\n",
      "        40        2325.5062         -42.5160            1.56m\n",
      "        22        2375.4829            5.26m\n",
      "        33        2324.6094            3.23m\n",
      "        41        2302.5612         -10.0003            1.40m\n",
      "        22         478.8371            8.48m\n",
      "        22         457.5020         -26.6403            4.33m\n",
      "        26         434.4872          15.8893            3.73m\n",
      "        22        2397.8446            5.25m\n",
      "        43        2302.1062          79.5086            1.09m\n",
      "        41        2323.4765           9.8016            1.40m\n",
      "        23        2371.7422            5.08m\n",
      "        34        2320.9501            3.04m\n",
      "        22         482.5787            8.66m\n",
      "        42        2296.4354          -6.8308            1.25m\n",
      "        23         460.8763          49.7399            4.19m\n",
      "        27         427.2401          -4.6939            3.58m\n",
      "        44        2277.6767         -80.1691           55.82s\n",
      "        42        2329.9859          43.7922            1.25m\n",
      "        23        2394.1296            5.08m\n",
      "        43        2315.5017          93.9274            1.09m\n",
      "        23         472.0582            8.17m\n",
      "        24        2368.0166            4.90m\n",
      "        35        2317.3591            2.84m\n",
      "        24         457.6900          15.9866            4.03m\n",
      "        28         432.2347          43.7499            3.43m\n",
      "        45        2289.4073          64.4343           46.51s\n",
      "        43        2309.9733         -62.2039            1.09m\n",
      "        24        2390.3591            4.91m\n",
      "        44        2296.7883         -57.2769           55.91s\n",
      "        23         475.3014            8.35m\n",
      "        25         442.9738         -30.5938            3.88m\n",
      "        36        2313.7917            2.65m\n",
      "        25        2364.3136            4.71m\n",
      "        29         421.2187         -24.4392            3.28m\n",
      "        46        2278.0539         -28.0531           37.18s\n",
      "        44        2317.4049          47.5555           56.13s\n",
      "        45        2281.9907         -41.8224           46.59s\n",
      "        24         465.7338            7.88m\n",
      "        25        2386.5986            4.72m\n",
      "        26         440.0474          15.8766            3.73m\n",
      "        47        2265.3808         -33.2763           27.88s\n",
      "        30         420.7751          17.2630            3.12m\n",
      "        37        2310.1875            2.46m\n",
      "        26        2360.6723            4.53m\n",
      "        45        2311.9823          -3.9743           46.82s\n",
      "        46        2311.0782         133.8108           37.26s\n",
      "        24         469.3449            8.04m\n",
      "        27         431.1919         -11.2839            3.58m\n",
      "        26        2382.8432            4.53m\n",
      "        48        2278.2920          69.1293           18.61s\n",
      "        31         423.5940          29.8436            2.97m\n",
      "        46        2308.9300           5.3542           37.44s\n",
      "        38        2306.5803            2.27m\n",
      "        27        2356.9784            4.35m\n",
      "        47        2287.9622         -75.0882           27.94s\n",
      "        25         460.1739            7.58m\n",
      "        28         433.6043          32.4724            3.42m\n",
      "        49        2278.0218          16.3764            9.31s\n",
      "        27        2379.0852            4.33m\n",
      "        32         413.3154         -25.3597            2.82m\n",
      "        47        2300.8271         -14.6075           28.07s\n",
      "        39        2302.9674            2.08m\n",
      "        48        2283.2850          -1.4033           18.61s\n",
      "        25         464.1875            7.72m\n",
      "        28        2353.2624            4.16m\n",
      "        29         428.8008          -0.1915            3.27m\n",
      "        50        2261.3467         -49.5098            0.00s\n",
      "        33         410.0627           2.7259            2.66m\n",
      "        48        2304.0542          30.4001           18.70s\n",
      "        28        2375.3513            4.13m\n",
      "        49        2291.3524          49.7845            9.31s\n",
      "        40        2299.3884            1.88m\n",
      "        26         455.6138            7.29m\n",
      "        29        2349.6037            3.97m\n",
      "        30         428.5880          18.6666            3.12m\n",
      "        49        2313.0947          53.9621            9.34s\n",
      "        34         406.3842           1.9254            2.51m\n",
      "        29        2371.6498            3.94m\n",
      "        50        2275.7473         -45.2087            0.00s\n",
      "        26         459.5936            7.41m\n",
      "        41        2295.8251            1.69m\n",
      "        31         417.1623         -25.7016            2.96m\n",
      "        50        2312.8981          16.9425            0.00s\n",
      "        30        2345.9432            3.77m\n",
      "        35         403.6313           4.9531            2.36m\n",
      "        30        2367.9238            3.75m\n",
      "        27         451.6467            6.99m\n",
      "        42        2292.2371            1.50m\n",
      "        32         415.4989           9.2255            2.81m\n",
      "        31        2342.2897            3.58m\n",
      "        36         397.8724          -8.4129            2.20m\n",
      "        27         454.5914            7.10m\n",
      "        31        2364.2154            3.56m\n",
      "        33         415.8871          17.3758            2.66m\n",
      "        43        2288.6548            1.31m\n",
      "        32        2338.6234            3.39m\n",
      "        37         394.8797           2.6618            2.05m\n",
      "        28         447.9263            6.69m\n",
      "        32        2360.5282            3.37m\n",
      "        34         406.6545         -19.8991            2.51m\n",
      "        44        2285.0701            1.13m\n",
      "        28         450.8764            6.79m\n",
      "        33        2334.9882            3.20m\n",
      "        38         397.4625          23.6026            1.90m\n",
      "        33        2356.8386            3.19m\n",
      "        35         403.6595           5.0505            2.36m\n",
      "        45        2281.5281           56.32s\n",
      "        29         444.6212            6.39m\n",
      "        39         392.5829          -5.1595            1.74m\n",
      "        34        2331.3193            3.01m\n",
      "        34        2353.1651            3.00m\n",
      "        36         400.9518           4.6838            2.21m\n",
      "        29         447.5610            6.49m\n",
      "        46        2277.9483           44.97s\n",
      "        40         383.0566         -25.1136            1.59m\n",
      "        35        2327.7012            2.82m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time= 9.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        37         400.3513          13.5663            2.06m\n",
      "        35        2349.5265            2.82m\n",
      "        30         441.1550            6.10m\n",
      "        47        2274.4484           33.73s\n",
      "        36        2324.0577            2.63m\n",
      "        41         378.5375          -4.6918            1.44m\n",
      "         1        2099.9319         349.9020            7.85m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time= 9.0min\n",
      "        30         444.2877            6.19m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        38         401.2575          19.8147            1.91m\n",
      "        36        2345.8495            2.63m\n",
      "        48        2270.9112           22.47s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time= 9.0min\n",
      "         2        1815.6260         336.7346            7.64m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        37        2320.4427            2.44m\n",
      "        42         382.2599          26.2598            1.28m\n",
      "        31         437.9399            5.80m\n",
      "         1        2077.6053            9.18m\n",
      "        39         396.9015          -3.9645            1.76m\n",
      "        37        2342.2320            2.44m\n",
      "        49        2267.3724           11.25s\n",
      "         3        1570.4507         229.0003            7.55m\n",
      "        43         377.4310          -6.4818            1.13m\n",
      "         1        2090.1663            9.49m\n",
      "        38        2316.8040            2.25m\n",
      "        31         441.0867            5.90m\n",
      "         2        1778.8452            8.80m\n",
      "        40         389.5755         -14.6409            1.60m\n",
      "        38        2338.5872            2.25m\n",
      "        50        2263.8375            0.00s\n",
      "         4        1369.4816         189.3159            7.43m\n",
      "        44         374.2075           0.5204           57.90s\n",
      "         2        1791.7546            9.03m\n",
      "        39        2313.1648            2.06m\n",
      "        32         434.3890            5.50m\n",
      "         3        1535.6809            8.56m\n",
      "        41         385.3810          -4.1150            1.45m\n",
      "         5        1220.7994         211.8699            7.17m\n",
      "        39        2334.9782            2.06m\n",
      "        45         380.5415          35.8060           48.46s\n",
      "        40        2309.5640            1.87m\n",
      "         3        1546.8533            8.78m\n",
      "        32         437.7222            5.60m\n",
      "         6        1078.3324         100.6457            6.99m\n",
      "        42         383.4365           5.0059            1.29m\n",
      "         4        1335.8774            8.45m\n",
      "        40        2331.3359            1.87m\n",
      "        33         431.3901            5.20m\n",
      "        46         370.5385         -29.7572           38.89s\n",
      "        41        2305.9617            1.68m\n",
      "         4        1347.7008            8.70m\n",
      "         7         972.0514         120.0928            6.87m\n",
      "         5        1174.7397            8.35m\n",
      "        43         385.0839          19.5241            1.13m\n",
      "        41        2327.7308            1.69m\n",
      "        33         434.5447            5.29m\n",
      "        47         369.1133           6.9063           29.26s\n",
      "        42        2302.3725            1.50m\n",
      "         5        1184.9745            8.41m\n",
      "         8         871.8181          56.3486            6.65m\n",
      "         6        1042.2206            8.15m\n",
      "        44         380.8846          -3.8533           58.49s\n",
      "        34         428.5871            4.90m\n",
      "        42        2324.1074            1.50m\n",
      "         9         810.1337         126.0336           76.46m\n",
      "        43        2298.8358            3.81m\n",
      "        48         371.0816          20.7501           58.02s\n",
      "         6        1050.8921          120.90m\n",
      "         7         934.4004          102.39m\n",
      "        45         377.1331          -3.0897            2.52m\n",
      "        34         431.5898           12.22m\n",
      "        43        2320.5145            3.81m\n",
      "        10         745.0527          46.7206           67.74m\n",
      "        49         369.5262           6.2751           28.62s\n",
      "        44        2295.2681            3.22m\n",
      "         7         942.6761          102.43m\n",
      "        35         425.7482           11.19m\n",
      "         8         844.9643           88.44m\n",
      "        11         694.3975          52.0302           60.56m\n",
      "        46         378.7725          17.4153            1.99m\n",
      "        44        2316.9014            3.22m\n",
      "        45        2291.6955            2.64m\n",
      "        50         362.6891         -17.0475            0.00s\n",
      "         8         852.8025           88.60m\n",
      "        35         428.9275           11.27m\n",
      "        12         658.8062          67.9596           54.58m\n",
      "         9         772.0079           77.57m\n",
      "        47         372.0557         -15.3675            1.47m\n",
      "        45        2313.2859            2.64m\n",
      "        46        2288.1138            2.08m\n",
      "        36         423.3035           10.28m\n",
      "         9         779.4129           77.71m\n",
      "        13         613.0741          -9.2173           49.48m\n",
      "        10         712.1871           68.85m\n",
      "        48         371.1468           9.2275           58.12s\n",
      "        46        2309.7075            2.08m\n",
      "        47        2284.6233            1.54m\n",
      "        14         585.9476          35.7119           45.10m\n",
      "        36         426.1316           10.35m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=26.3min\n",
      "        10         718.8989           68.98m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        11         662.5526           61.71m\n",
      "        47        2306.1541            1.54m\n",
      "        49         372.2945          15.8766           28.70s\n",
      "        37         420.9064            9.40m\n",
      "        15         569.3665          56.5111           41.29m\n",
      "        48        2281.0759            1.01m\n",
      "         1        2107.6962            8.86m\n",
      "        11         668.8463           61.83m\n",
      "        12         622.4784           55.71m\n",
      "        48        2302.5835            1.01m\n",
      "        50         367.8481          -7.9632            0.00s\n",
      "        16         539.5715         -15.8308           37.92m\n",
      "        37         423.6140            9.47m\n",
      "        49        2277.5579           30.02s\n",
      "         2        1803.9688            8.74m\n",
      "        12         628.3104           55.82m\n",
      "        17         523.3105          21.0860           34.95m\n",
      "        38         417.8518            8.55m\n",
      "        13         589.5037           50.62m\n",
      "        49        2298.9855           30.01s\n",
      "        50        2274.0546            0.00s\n",
      "         3        1555.8086            8.80m\n",
      "        13         594.1823           50.75m\n",
      "        18         512.9601          31.0269           32.29m\n",
      "        14         561.5141           46.22m\n",
      "        50        2295.4725            0.00s\n",
      "        38         421.2052            8.62m\n",
      "         4        1354.7313            8.56m\n",
      "        19         499.4431           8.7289           29.90m\n",
      "        39         415.1487            7.73m\n",
      "        14         565.8954           46.37m\n",
      "        15         537.9787           42.40m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=24.9min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        20         480.4202         -24.0823           27.73m\n",
      "         5        1193.7657            8.41m\n",
      "        39         419.2435            7.79m\n",
      "        15         542.0012           42.56m\n",
      "        16         518.9551           39.06m\n",
      "        21         480.9852          49.7159           25.78m\n",
      "        40         412.3282            6.94m\n",
      "         6        1059.2613            8.37m\n",
      "        16         522.4118           39.24m\n",
      "         1        2446.0963           3.6007            3.00m\n",
      "        17         502.2591           36.12m\n",
      "        22         472.3412           6.6737           23.98m\n",
      "         7         951.5699            8.22m\n",
      "        40         416.6413            7.00m\n",
      "        17         505.5140           36.25m\n",
      "        18         488.4300           33.43m\n",
      "        23         462.9553          -0.5498           22.35m\n",
      "        41         409.7571            6.17m\n",
      "         8         863.0235            8.19m\n",
      "         2        2452.7592          46.0703            2.72m\n",
      "        24         453.0799          -6.6247           20.82m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=25.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        18         491.4818           33.64m\n",
      "        19         476.4209           31.06m\n",
      "        41         413.4466            6.23m\n",
      "         9         789.5307            8.12m\n",
      "        25         454.1787          34.2511           19.44m\n",
      "        42         407.5918            5.43m\n",
      "        19         479.2935           31.28m\n",
      "        20         466.2249           28.92m\n",
      "         3        2455.2356          29.3730            2.46m\n",
      "        10         728.9765            8.03m\n",
      "         1        2455.4777           3.6181            3.30m\n",
      "        26         444.2405         -14.2669           18.12m\n",
      "        20         469.0225           29.12m\n",
      "        42         410.5936            5.49m\n",
      "        21         457.2510           26.95m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=26.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        27         434.3259         -17.8894           16.88m\n",
      "        11         678.6812            7.98m\n",
      "        43         403.5041            4.71m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=26.4min\n",
      "         4        2431.5556         -75.3434            2.14m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         2        2459.7723          36.6140            2.91m\n",
      "        21         460.0435           27.12m\n",
      "        22         448.3866           25.13m\n",
      "        28         431.9395          10.4600           15.71m\n",
      "        12         637.4000            7.78m\n",
      "        43         408.2798            4.75m\n",
      "         1        2467.7940           3.7046            3.05m\n",
      "        29         430.6530          17.6671           14.61m\n",
      "        22         452.3038           25.28m\n",
      "        23         441.8115           23.43m\n",
      "        44         401.5566            3.99m\n",
      "        13         603.6416            7.54m\n",
      "         5        2423.4343         -13.1212            1.74m\n",
      "         3        2458.0216          12.4671            2.46m\n",
      "         1        2444.3765            3.49m\n",
      "        30         429.3269          14.9994           13.56m\n",
      "        23         445.2477           23.56m\n",
      "        24         435.6286           21.87m\n",
      "        14         574.8290            7.32m\n",
      "         2        2475.0074          48.4914            2.66m\n",
      "        44         405.6960            4.03m\n",
      "        31         426.5262           7.8935           12.58m\n",
      "        45         398.7207            3.29m\n",
      "         6        2438.2351          78.5421            1.37m\n",
      "         4        2428.8884         -97.0991            2.05m\n",
      "        25         430.1804           20.40m\n",
      "        24         438.8186           21.99m\n",
      "        15         550.9650            7.17m\n",
      "         2        2440.4397            3.09m\n",
      "        32         419.0583         -11.9797           11.64m\n",
      "         3        2467.4423         -10.6996            2.32m\n",
      "        45         403.2764            3.32m\n",
      "        25         433.4667           20.52m\n",
      "        26         425.2980           19.03m\n",
      "        16         531.6725            6.95m\n",
      "         7        2415.6493         -71.1489            1.02m\n",
      "        33         419.4823          19.9006           10.76m\n",
      "        46         395.8868            2.61m\n",
      "         5        2428.9664          19.6978            1.70m\n",
      "        34         413.2870          -8.6411            9.92m\n",
      "        27         420.6035           17.77m\n",
      "        17         514.3143            6.82m\n",
      "        26         428.7026           19.17m\n",
      "         3        2436.5111            2.80m\n",
      "         4        2453.3714         -36.7244            2.04m\n",
      "        46         400.3871            2.63m\n",
      "         8        2425.5448          58.8299           40.99s\n",
      "        47         393.7268            1.93m\n",
      "        35         414.9814          22.3655            9.11m\n",
      "         6        2442.7513          74.4743            1.36m\n",
      "        18         500.1367            6.59m\n",
      "        28         416.2194           16.56m\n",
      "        27         424.0628           17.87m\n",
      "        36         405.4567         -22.3036            8.34m\n",
      "         5        2474.4498         103.8871            1.68m\n",
      "        19         487.8319            6.38m\n",
      "         4        2432.5901            2.37m\n",
      "        29         412.3750           15.42m\n",
      "        28         420.0105           16.67m\n",
      "         9        2418.9373          -7.2385           20.36s\n",
      "        47         398.4035            1.95m\n",
      "        48         389.8816            1.28m\n",
      "         7        2413.7900         -96.5649            1.01m\n",
      "        37         405.8724          16.2475            7.59m\n",
      "        20         477.2993            6.18m\n",
      "        30         408.8421           14.35m\n",
      "        29         415.8627           15.53m\n",
      "        38         405.2439          14.5189            6.88m\n",
      "         6        2459.0396         -42.2088            1.34m\n",
      "        10        2394.5963         -78.2728            0.00s\n",
      "         5        2428.6769            1.96m\n",
      "        48         394.7763            1.29m\n",
      "        21         467.1656            5.97m\n",
      "         8        2433.7042          98.9779           40.16s\n",
      "        49         387.2278           37.94s\n",
      "        39         402.7545           5.3095            6.19m\n",
      "        31         405.8770           13.32m\n",
      "        30         412.4065           14.44m\n",
      "         7        2453.7099          -1.8807           59.60s\n",
      "        22         458.9840            5.78m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 3.7min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        40         394.4644         -20.8853            5.53m\n",
      "        32         402.5731           12.35m\n",
      "        31         409.2210           13.41m\n",
      "         9        2424.2730         -18.5258           20.00s\n",
      "        49         392.5686           38.32s\n",
      "         6        2424.7716            1.57m\n",
      "        50         383.0997            0.00s\n",
      "        41         392.6559           6.4134            4.90m\n",
      "        23         452.1530            5.58m\n",
      "        33         399.4307           11.42m\n",
      "         8        2443.4033         -21.8259           39.46s\n",
      "        32         405.6896           12.44m\n",
      "        42         390.6149           5.5645            4.28m\n",
      "         1        2455.3525            3.44m\n",
      "        24         445.9391            5.38m\n",
      "        10        2409.8138         -38.6671            0.00s\n",
      "        50         391.0244            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=31.7min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        34         396.3790           10.53m\n",
      "         7        2420.8741            1.17m\n",
      "        33         402.6546           11.52m\n",
      "        43         386.2405          -3.9843            3.69m\n",
      "         9        2465.2608         106.8184           19.61s\n",
      "        25         440.4471            5.18m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 3.6min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        35         393.7524            9.68m\n",
      "        44         383.6972           1.5200            3.12m\n",
      "[CV] END learning_rate=0.1, max_depth=20, max_features=1.0, n_estimators=50, subsample=1.0; total time=31.9min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        34         399.7721           10.62m\n",
      "         2        2451.4018            3.05m\n",
      "        26         435.5566            4.98m\n",
      "         1        2478.2360            3.46m\n",
      "         8        2416.9846           46.55s\n",
      "        10        2444.5736         -63.3824            0.00s\n",
      "        36         391.2411            8.88m\n",
      "        45         379.7238          -2.4715            2.56m\n",
      "        35         396.6562            9.77m\n",
      "         1        2075.0257         341.2701            2.75m\n",
      "        27         430.8219            4.78m\n",
      "         1        2081.7479         342.6916            2.78m\n",
      "        37         388.8272            8.09m\n",
      "        46         381.5804          19.1748            2.02m\n",
      "         3        2447.4590            2.65m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 3.5min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        36         394.0031            8.95m\n",
      "         2        2474.2604            3.12m\n",
      "         9        2413.1027           23.24s\n",
      "        28         426.2064            4.58m\n",
      "         2        1783.1459         335.8800            2.48m\n",
      "        47         373.0254         -22.8451            1.50m\n",
      "        38         386.3392            7.34m\n",
      "         2        1787.5622         327.9811            2.49m\n",
      "        37         391.5456            8.17m\n",
      "        29         421.9975            4.38m\n",
      "         1        2093.6574         350.8304            2.82m\n",
      "        48         376.1825          23.1201           59.10s\n",
      "         4        2443.5242            2.27m\n",
      "        39         383.6344            6.62m\n",
      "         3        1541.5754         262.9955            2.18m\n",
      "         3        2470.2926            2.73m\n",
      "        10        2409.2285            0.00s\n",
      "        38         388.8863            7.42m\n",
      "         3        1546.0404         261.5651            2.18m\n",
      "        49         374.7204           4.5787           29.18s\n",
      "        30         418.2759            4.17m\n",
      "        40         381.2850            5.93m\n",
      "         2        1800.0411         345.6732            2.55m\n",
      "        39         386.4122            6.69m\n",
      "         5        2439.5972            1.89m\n",
      "        31         414.8424            3.96m\n",
      "        50         374.4591           9.8876            0.00s\n",
      "         4        1330.5055         153.1784            1.85m\n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 4.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4        1329.5639         136.4938            1.87m\n",
      "         4        2466.3327            2.34m\n",
      "        41         378.9912            5.25m\n",
      "        40         383.9959            5.98m\n",
      "        32         411.5115            3.76m\n",
      "         3        1549.5146         232.2761            2.24m\n",
      "         5        1165.0075         150.4409            1.55m\n",
      "        42         376.6855            4.60m\n",
      "         6        2435.6780            1.51m\n",
      "         5        1168.7412         169.5879            1.54m\n",
      "        33         408.4387            3.55m\n",
      "         1        2073.3920            3.39m\n",
      "        41         381.3261            5.30m\n",
      "         5        2462.3808            1.94m\n",
      "         4        1346.7093         196.5749            1.91m\n",
      "        43         374.5762            3.97m\n",
      "        34         405.5105            3.34m\n",
      "         6        1040.5947         167.8103            1.24m\n",
      "        42         379.0893            4.65m\n",
      "         6        1045.7374         172.9699            1.24m\n",
      "         7        2431.7667            1.14m\n",
      "        44         372.5464            3.35m\n",
      "         2        1769.5155            2.99m\n",
      "        35         402.9536            3.13m\n",
      "         5        1194.1593         214.3458            1.58m\n",
      "         6        2458.4367            1.55m\n",
      "        43         376.6706            4.01m\n",
      "         7         929.0884          91.7940           55.92s\n",
      "         7         925.7941          63.1867           55.60s\n",
      "        45         370.1584            2.76m\n",
      "        36         400.0312            2.93m\n",
      "         8        2427.8633           45.46s\n",
      "        44         374.4547            3.39m\n",
      "         6        1052.7257          99.9083            1.27m\n",
      "         3        1522.8500            2.64m\n",
      "        46         368.3257            2.18m\n",
      "         8         840.2832          89.1705           37.25s\n",
      "         7        2454.5006            1.16m\n",
      "        37         397.3403            2.72m\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=0.8; total time=25.3min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         8         848.2732         137.3759           37.07s\n",
      "        45         372.1627            2.79m\n",
      "         7         946.4567         122.5045           56.91s\n",
      "        47         366.0736            1.62m\n",
      "        38         394.5844            2.52m\n",
      "         9        2423.9676           22.85s\n",
      "         4        1322.4720            2.29m\n",
      "         9         765.9095          66.2975           18.72s\n",
      "         9         769.5783          47.8748           18.57s\n",
      "        46         369.6728            2.21m\n",
      "         8        2450.5712           46.66s\n",
      "         1        2083.0624            3.53m\n",
      "        39         391.5572            2.31m\n",
      "        48         364.0953            1.07m\n",
      "         8         848.1259          54.8866           38.10s\n",
      "        47         367.1584            1.64m\n",
      "        10         695.4781          14.3797            0.00s\n",
      "        10        2420.0797            0.00s\n",
      "        10         703.3421          36.6718            0.00s\n",
      "         5        1159.5679            1.91m\n",
      "        40         388.9051            2.11m\n",
      "        49         362.1840           31.61s\n",
      "         9        2446.6497           23.33s\n",
      "         2        1777.9878            3.10m\n",
      "         9         786.6377         124.7155           19.05s\n",
      "        48         364.8955            1.08m\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 3.4min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        41         386.7409            1.90m\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 3.4min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 4.1min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "        50         360.4221            0.00s\n",
      "         6        1026.9977            1.53m\n",
      "         1        2446.1475           3.5602            1.39m\n",
      "         1        2455.5306           3.5977            1.36m\n",
      "        49         362.6989           31.98s\n",
      "        42         384.6662            1.69m\n",
      "        10        2442.7363            0.00s\n",
      "        10         721.6140          44.8729            0.00s\n",
      "         3        1530.5575            2.71m\n",
      "         2        2452.8888          46.0231            1.21m\n",
      "         2        2459.8813          36.5628            1.24m\n",
      "         1        2103.5904            3.55m\n",
      "        43         382.3978            1.48m\n",
      "        50         360.5376            0.00s\n",
      "         3        2455.4768          29.2666            1.07m\n",
      "         3        2458.2373          12.3725            1.08m\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=0.8; total time= 3.5min\n",
      "         7         918.9237            1.14m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "[CV] END learning_rate=0.001, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 4.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4        2431.8550         -75.4120           54.76s\n",
      "         4        2429.1529         -97.1861           55.57s\n",
      "         4        1329.4721            2.30m\n",
      "        44         380.3088            1.27m\n",
      "         1        2467.8601           3.6929            1.44m\n",
      "         2        1796.4138            3.08m\n",
      "         1        2444.4208            1.63m\n",
      "         5        2423.7871         -13.1971           45.19s\n",
      "         5        2429.3095          19.6475           46.58s\n",
      "         2        2475.1592          48.4094            1.29m\n",
      "        45         378.1074            1.06m\n",
      "         8         830.6580           45.78s\n",
      "         6        2438.6351          78.4824           36.35s\n",
      "         2        2440.5716            1.45m\n",
      "         6        2443.1427          74.3884           37.37s\n",
      "         3        2467.6376         -10.7431            1.13m\n",
      "         5        1165.9968            1.92m\n",
      "         7        2416.1034         -71.2471           27.44s\n",
      "        46         375.9484           50.94s\n",
      "         7        2414.2015         -96.5920           27.99s\n",
      "         3        1547.0923            2.69m\n",
      "         3        2436.6977            1.30m\n",
      "         4        2453.6522         -36.8402           57.78s\n",
      "         8        2426.0859          58.9265           18.35s\n",
      "         8        2434.2142          98.9136           18.65s\n",
      "         9         758.2932           22.93s\n",
      "         4        2432.8827            1.11m\n",
      "        47         373.2302           38.24s\n",
      "         5        2474.8210         103.7498           47.97s\n",
      "         9        2419.5491          -7.4180            9.22s\n",
      "         6        1032.5662            1.53m\n",
      "         9        2424.8218         -18.5862            9.34s\n",
      "         6        2459.5123         -42.2068           38.44s\n",
      "         5        2429.0861           55.54s\n",
      "         4        1344.8264            2.30m\n",
      "        10        2395.2742         -78.3792            0.00s\n",
      "        48         371.0489           25.57s\n",
      "        10        2410.4258         -38.7082            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=27.6min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         7        2454.2412          -1.9431           28.54s\n",
      "        10         698.8416            0.00s\n",
      "         6        2425.2442           44.70s\n",
      "         7         923.8037            1.14m\n",
      "         8        2443.9538         -21.9258           18.81s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 1.8min\n",
      "         1        2455.4272            1.57m\n",
      "      Iter       Train Loss   Remaining Time \n",
      "        49         368.3673           12.81s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 1.8min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         7        2421.4493           33.50s\n",
      "         5        1179.9107            1.91m\n",
      "         9        2465.9467         106.7976            9.42s\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 4.1min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         2        2451.6087            1.46m\n",
      "         1        2478.2792            1.67m\n",
      "         1        2079.9004         337.6045            1.38m\n",
      "        50         366.1715            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=28.0min\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         8        2417.6028           22.52s\n",
      "        10        2445.3478         -63.4645            0.00s\n",
      "         1        2086.7749         340.8753            1.35m\n",
      "         2        1792.0589         333.1727            1.22m\n",
      "         2        2474.5050            1.45m\n",
      "         8         835.0826           45.73s\n",
      "         3        2447.7062            1.28m\n",
      "         1        2099.9319         349.9020            1.46m\n",
      "         9        2413.7674           11.23s\n",
      "         6        1045.8448            1.53m\n",
      "         2        1797.3942         322.6655            1.22m\n",
      "         3        1557.3536         256.8837            1.08m\n",
      "         3        2470.5720            1.28m\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 1.8min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         4        2443.8323            1.13m\n",
      "         2        1815.6260         336.7346            1.28m\n",
      "         3        1559.5971         260.3183            1.08m\n",
      "        10        2409.9588            0.00s\n",
      "         4        1350.4929         148.7885           55.12s\n",
      "         4        2466.6763            1.10m\n",
      "         3        1570.4507         229.0003            1.11m\n",
      "         1        2077.6053            1.61m\n",
      "         5        2439.9873           55.61s\n",
      "         9         762.2449           22.90s\n",
      "         4        1346.2350         133.1985           54.51s\n",
      "         5        1187.2908         150.1191           45.80s\n",
      "         7         936.5386            1.14m\n",
      "         4        1369.4816         189.3159           57.63s\n",
      "         5        2462.7578           54.73s\n",
      "         2        1778.8452            1.42m\n",
      "         6        2436.1292           44.28s\n",
      "         5        1185.2628         168.6082           45.36s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.2min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         6        1062.5839         165.5808           36.60s\n",
      "         5        1220.7994         211.8699           47.77s\n",
      "         6        1064.2292         171.6890           36.42s\n",
      "         3        1535.6809            1.25m\n",
      "         6        2458.9051           44.03s\n",
      "         7        2432.2712           33.46s\n",
      "         7         950.5911          89.7893           27.47s\n",
      "        10         702.5223            0.00s\n",
      "         1        2090.1663            1.68m\n",
      "         6        1078.3324         100.6457           37.77s\n",
      "         8         846.9734           45.78s\n",
      "         7         942.9154          59.8402           27.29s\n",
      "         8         863.7993          95.2186           18.31s\n",
      "         7        2455.1097           32.96s\n",
      "         4        1335.8774            1.08m\n",
      "         8        2428.4317           22.12s\n",
      "         2        1791.7546            1.46m\n",
      "         7         972.0514         120.0928           28.09s\n",
      "         8         867.3120         139.8881           18.20s\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 4.1min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         9         789.0292          62.4035            9.19s\n",
      "         5        1174.7397           54.42s\n",
      "         8        2451.2307           22.06s\n",
      "         9        2424.6182           11.03s\n",
      "         3        1546.8533            1.27m\n",
      "         8         871.8181          56.3486           18.69s\n",
      "         9         787.5214          46.4199            9.13s\n",
      "        10         717.6830          12.1592            0.00s\n",
      "         1        2107.6962            1.57m\n",
      "         9         773.6413           22.85s\n",
      "         9        2447.3441           10.96s\n",
      "         9         810.1337         126.0336            9.22s\n",
      "         6        1042.2206           43.44s\n",
      "        10        2420.8072            0.00s\n",
      "         4        1347.7008            1.09m\n",
      "        10         722.7218          36.9872            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=50, subsample=1.0; total time=12.2min\n",
      "         2        1803.9688            1.39m\n",
      "        10         745.0527          46.7206            0.00s\n",
      "        10        2443.4888            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 1.8min\n",
      "         7         934.4004           32.39s\n",
      "         5        1184.9745           53.18s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.1min\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 1.7min\n",
      "         3        1555.8086            1.19m\n",
      "        10         713.5376            0.00s\n",
      "         8         844.9643           21.04s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=0.8; total time= 1.7min\n",
      "         6        1050.8921           41.10s\n",
      "[CV] END learning_rate=0.001, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 2.0min\n",
      "         4        1354.7313           57.53s\n",
      "         9         772.0079           10.22s\n",
      "         7         942.6761           29.76s\n",
      "[CV] END learning_rate=0.1, max_depth=70, max_features=1.0, n_estimators=10, subsample=1.0; total time= 4.0min\n",
      "         5        1193.7657           46.11s\n",
      "        10         712.1871            0.00s\n",
      "         8         852.8025           19.30s\n",
      "         6        1059.2613           35.43s\n",
      "         9         779.4129            9.36s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 1.8min\n",
      "         7         951.5699           25.85s\n",
      "        10         718.8989            0.00s\n",
      "         8         863.0235           16.85s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 1.7min\n",
      "         9         789.5307            8.19s\n",
      "        10         728.9765            0.00s\n",
      "[CV] END learning_rate=0.1, max_depth=100, max_features=sqrt, n_estimators=10, subsample=1.0; total time= 1.5min\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1        2095.5957           14.98m\n",
      "         2        1797.3790           14.55m\n",
      "         3        1555.5603           14.38m\n",
      "         4        1359.0769           14.14m\n",
      "         5        1199.2794           13.77m\n",
      "         6        1069.3016           13.46m\n",
      "         7         962.2426           13.13m\n",
      "         8         874.9294           12.76m\n",
      "         9         803.5222           12.42m\n",
      "        10         744.9287           12.08m\n",
      "        11         697.1438           11.75m\n",
      "        12         657.5696           11.41m\n",
      "        13         625.0702           11.09m\n",
      "        14         598.1872           10.77m\n",
      "        15         575.9502           10.47m\n",
      "        16         557.6187           10.16m\n",
      "        17         542.2850            9.85m\n",
      "        18         529.3296            9.55m\n",
      "        19         518.3694            9.26m\n",
      "        20         508.9820            8.96m\n",
      "        21         501.0634            8.66m\n",
      "        22         494.0238            8.36m\n",
      "        23         487.7152            8.07m\n",
      "        24         482.4515            7.77m\n",
      "        25         478.0171            7.47m\n",
      "        26         473.8773            7.18m\n",
      "        27         470.3716            6.89m\n",
      "        28         467.3668            6.60m\n",
      "        29         464.4183            6.31m\n",
      "        30         461.7406            6.02m\n",
      "        31         459.2661            5.73m\n",
      "        32         457.1009            5.44m\n",
      "        33         454.7536            5.14m\n",
      "        34         452.0557            4.84m\n",
      "        35         449.5059            4.55m\n",
      "        36         447.0068            4.25m\n",
      "        37         444.8732            3.95m\n",
      "        38         443.1336            3.65m\n",
      "        39         440.9878            3.36m\n",
      "        40         438.4306            3.06m\n",
      "        41         435.8960            2.76m\n",
      "        42         433.2284            2.45m\n",
      "        43         431.3863            2.15m\n",
      "        44         429.4205            1.84m\n",
      "        45         427.8659            1.54m\n",
      "        46         425.4638            1.23m\n",
      "        47         423.4216           55.60s\n",
      "        48         421.3331           37.14s\n",
      "        49         418.4475           18.58s\n",
      "        50         416.8504            0.00s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingRegressor(min_samples_leaf=7,\n",
       "                                                 min_samples_split=14,\n",
       "                                                 random_state=42, verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [20],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [70],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]}],\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingRegressor(min_samples_leaf=7,\n",
       "                                                 min_samples_split=14,\n",
       "                                                 random_state=42, verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [20],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [50],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [70],\n",
       "                          &#x27;max_features&#x27;: [1.0], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]},\n",
       "                         {&#x27;learning_rate&#x27;: [0.001, 0.1], &#x27;max_depth&#x27;: [100],\n",
       "                          &#x27;max_features&#x27;: [&#x27;sqrt&#x27;], &#x27;n_estimators&#x27;: [10],\n",
       "                          &#x27;subsample&#x27;: [0.8, 1.0]}],\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, response_method=&#x27;predict&#x27;),\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(min_samples_leaf=7, min_samples_split=14,\n",
       "                          random_state=42, verbose=2)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(min_samples_leaf=7, min_samples_split=14,\n",
       "                          random_state=42, verbose=2)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=GradientBoostingRegressor(min_samples_leaf=7,\n",
       "                                                 min_samples_split=14,\n",
       "                                                 random_state=42, verbose=2),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'learning_rate': [0.001, 0.1], 'max_depth': [20],\n",
       "                          'max_features': [1.0], 'n_estimators': [50],\n",
       "                          'subsample': [0.8, 1.0]},\n",
       "                         {'learning_rate': [0.001, 0.1], 'max_depth': [100],\n",
       "                          'max_features': ['sqrt'], 'n_estimators': [50],\n",
       "                          'subsample': [0.8, 1.0]},\n",
       "                         {'learning_rate': [0.001, 0.1], 'max_depth': [70],\n",
       "                          'max_features': [1.0], 'n_estimators': [10],\n",
       "                          'subsample': [0.8, 1.0]},\n",
       "                         {'learning_rate': [0.001, 0.1], 'max_depth': [100],\n",
       "                          'max_features': ['sqrt'], 'n_estimators': [10],\n",
       "                          'subsample': [0.8, 1.0]}],\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False, response_method='predict'),\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>824.113388</td>\n",
       "      <td>1.878284</td>\n",
       "      <td>24.542416</td>\n",
       "      <td>0.574201</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 20, 'max...</td>\n",
       "      <td>-2318.018213</td>\n",
       "      <td>-2295.067351</td>\n",
       "      <td>-2251.189625</td>\n",
       "      <td>-2288.091730</td>\n",
       "      <td>27.724953</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>976.878546</td>\n",
       "      <td>4.867375</td>\n",
       "      <td>24.139536</td>\n",
       "      <td>0.422584</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 20, 'max...</td>\n",
       "      <td>-2318.340719</td>\n",
       "      <td>-2295.121782</td>\n",
       "      <td>-2251.459101</td>\n",
       "      <td>-2288.307200</td>\n",
       "      <td>27.726240</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848.106457</td>\n",
       "      <td>2.014832</td>\n",
       "      <td>18.757970</td>\n",
       "      <td>0.164608</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 20, 'max_f...</td>\n",
       "      <td>-696.876129</td>\n",
       "      <td>-681.276981</td>\n",
       "      <td>-660.568192</td>\n",
       "      <td>-679.573768</td>\n",
       "      <td>14.871500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1601.343276</td>\n",
       "      <td>407.546955</td>\n",
       "      <td>18.773268</td>\n",
       "      <td>0.257926</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 20, 'max_f...</td>\n",
       "      <td>-699.300984</td>\n",
       "      <td>-674.536214</td>\n",
       "      <td>-657.729879</td>\n",
       "      <td>-677.189026</td>\n",
       "      <td>17.074684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>465.774580</td>\n",
       "      <td>0.747940</td>\n",
       "      <td>75.713643</td>\n",
       "      <td>0.302435</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2319.249347</td>\n",
       "      <td>-2296.043170</td>\n",
       "      <td>-2251.982223</td>\n",
       "      <td>-2289.091580</td>\n",
       "      <td>27.898147</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1175.816116</td>\n",
       "      <td>433.798542</td>\n",
       "      <td>405.982183</td>\n",
       "      <td>430.613700</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2319.299791</td>\n",
       "      <td>-2295.984484</td>\n",
       "      <td>-2251.695269</td>\n",
       "      <td>-2288.993181</td>\n",
       "      <td>28.038683</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1425.332277</td>\n",
       "      <td>12.471653</td>\n",
       "      <td>80.113964</td>\n",
       "      <td>2.595886</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-729.294640</td>\n",
       "      <td>-708.990934</td>\n",
       "      <td>-693.492956</td>\n",
       "      <td>-710.592843</td>\n",
       "      <td>14.659803</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1262.500760</td>\n",
       "      <td>438.808191</td>\n",
       "      <td>93.625358</td>\n",
       "      <td>1.798932</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-744.741826</td>\n",
       "      <td>-721.977079</td>\n",
       "      <td>-700.457820</td>\n",
       "      <td>-722.392242</td>\n",
       "      <td>18.081253</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>199.383369</td>\n",
       "      <td>3.008048</td>\n",
       "      <td>15.855541</td>\n",
       "      <td>0.104670</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 70, 'max...</td>\n",
       "      <td>-2456.511594</td>\n",
       "      <td>-2434.369612</td>\n",
       "      <td>-2388.889528</td>\n",
       "      <td>-2426.590245</td>\n",
       "      <td>28.149303</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>232.234825</td>\n",
       "      <td>1.810553</td>\n",
       "      <td>17.998962</td>\n",
       "      <td>0.219986</td>\n",
       "      <td>0.001</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 70, 'max...</td>\n",
       "      <td>-2456.561918</td>\n",
       "      <td>-2434.296392</td>\n",
       "      <td>-2388.924054</td>\n",
       "      <td>-2426.594122</td>\n",
       "      <td>28.145028</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>189.065885</td>\n",
       "      <td>2.244555</td>\n",
       "      <td>15.030953</td>\n",
       "      <td>0.178055</td>\n",
       "      <td>0.1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 70, 'max_f...</td>\n",
       "      <td>-896.406542</td>\n",
       "      <td>-869.390722</td>\n",
       "      <td>-843.901253</td>\n",
       "      <td>-869.899506</td>\n",
       "      <td>21.438214</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>228.601888</td>\n",
       "      <td>1.403186</td>\n",
       "      <td>15.739143</td>\n",
       "      <td>2.652205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 70, 'max_f...</td>\n",
       "      <td>-909.226852</td>\n",
       "      <td>-877.400983</td>\n",
       "      <td>-852.959405</td>\n",
       "      <td>-879.862413</td>\n",
       "      <td>23.036932</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93.747771</td>\n",
       "      <td>1.017397</td>\n",
       "      <td>15.007939</td>\n",
       "      <td>0.186280</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2457.006047</td>\n",
       "      <td>-2434.705436</td>\n",
       "      <td>-2389.362941</td>\n",
       "      <td>-2427.024808</td>\n",
       "      <td>28.144170</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>110.827942</td>\n",
       "      <td>1.627176</td>\n",
       "      <td>15.787429</td>\n",
       "      <td>1.788877</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.001, 'max_depth': 100, 'ma...</td>\n",
       "      <td>-2457.025230</td>\n",
       "      <td>-2434.720099</td>\n",
       "      <td>-2389.349638</td>\n",
       "      <td>-2427.031656</td>\n",
       "      <td>28.158250</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>92.155740</td>\n",
       "      <td>0.080669</td>\n",
       "      <td>12.766484</td>\n",
       "      <td>0.912627</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-897.498121</td>\n",
       "      <td>-869.524020</td>\n",
       "      <td>-845.449851</td>\n",
       "      <td>-870.823997</td>\n",
       "      <td>21.268491</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90.880640</td>\n",
       "      <td>8.076366</td>\n",
       "      <td>8.625143</td>\n",
       "      <td>1.474120</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 100, 'max_...</td>\n",
       "      <td>-907.426451</td>\n",
       "      <td>-878.058139</td>\n",
       "      <td>-854.168598</td>\n",
       "      <td>-879.884396</td>\n",
       "      <td>21.780743</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      824.113388      1.878284        24.542416        0.574201   \n",
       "1      976.878546      4.867375        24.139536        0.422584   \n",
       "2      848.106457      2.014832        18.757970        0.164608   \n",
       "3     1601.343276    407.546955        18.773268        0.257926   \n",
       "4      465.774580      0.747940        75.713643        0.302435   \n",
       "5     1175.816116    433.798542       405.982183      430.613700   \n",
       "6     1425.332277     12.471653        80.113964        2.595886   \n",
       "7     1262.500760    438.808191        93.625358        1.798932   \n",
       "8      199.383369      3.008048        15.855541        0.104670   \n",
       "9      232.234825      1.810553        17.998962        0.219986   \n",
       "10     189.065885      2.244555        15.030953        0.178055   \n",
       "11     228.601888      1.403186        15.739143        2.652205   \n",
       "12      93.747771      1.017397        15.007939        0.186280   \n",
       "13     110.827942      1.627176        15.787429        1.788877   \n",
       "14      92.155740      0.080669        12.766484        0.912627   \n",
       "15      90.880640      8.076366         8.625143        1.474120   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features param_n_estimators  \\\n",
       "0                0.001              20                1.0                 50   \n",
       "1                0.001              20                1.0                 50   \n",
       "2                  0.1              20                1.0                 50   \n",
       "3                  0.1              20                1.0                 50   \n",
       "4                0.001             100               sqrt                 50   \n",
       "5                0.001             100               sqrt                 50   \n",
       "6                  0.1             100               sqrt                 50   \n",
       "7                  0.1             100               sqrt                 50   \n",
       "8                0.001              70                1.0                 10   \n",
       "9                0.001              70                1.0                 10   \n",
       "10                 0.1              70                1.0                 10   \n",
       "11                 0.1              70                1.0                 10   \n",
       "12               0.001             100               sqrt                 10   \n",
       "13               0.001             100               sqrt                 10   \n",
       "14                 0.1             100               sqrt                 10   \n",
       "15                 0.1             100               sqrt                 10   \n",
       "\n",
       "   param_subsample                                             params  \\\n",
       "0              0.8  {'learning_rate': 0.001, 'max_depth': 20, 'max...   \n",
       "1              1.0  {'learning_rate': 0.001, 'max_depth': 20, 'max...   \n",
       "2              0.8  {'learning_rate': 0.1, 'max_depth': 20, 'max_f...   \n",
       "3              1.0  {'learning_rate': 0.1, 'max_depth': 20, 'max_f...   \n",
       "4              0.8  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "5              1.0  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "6              0.8  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "7              1.0  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "8              0.8  {'learning_rate': 0.001, 'max_depth': 70, 'max...   \n",
       "9              1.0  {'learning_rate': 0.001, 'max_depth': 70, 'max...   \n",
       "10             0.8  {'learning_rate': 0.1, 'max_depth': 70, 'max_f...   \n",
       "11             1.0  {'learning_rate': 0.1, 'max_depth': 70, 'max_f...   \n",
       "12             0.8  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "13             1.0  {'learning_rate': 0.001, 'max_depth': 100, 'ma...   \n",
       "14             0.8  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "15             1.0  {'learning_rate': 0.1, 'max_depth': 100, 'max_...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0        -2318.018213       -2295.067351       -2251.189625     -2288.091730   \n",
       "1        -2318.340719       -2295.121782       -2251.459101     -2288.307200   \n",
       "2         -696.876129        -681.276981        -660.568192      -679.573768   \n",
       "3         -699.300984        -674.536214        -657.729879      -677.189026   \n",
       "4        -2319.249347       -2296.043170       -2251.982223     -2289.091580   \n",
       "5        -2319.299791       -2295.984484       -2251.695269     -2288.993181   \n",
       "6         -729.294640        -708.990934        -693.492956      -710.592843   \n",
       "7         -744.741826        -721.977079        -700.457820      -722.392242   \n",
       "8        -2456.511594       -2434.369612       -2388.889528     -2426.590245   \n",
       "9        -2456.561918       -2434.296392       -2388.924054     -2426.594122   \n",
       "10        -896.406542        -869.390722        -843.901253      -869.899506   \n",
       "11        -909.226852        -877.400983        -852.959405      -879.862413   \n",
       "12       -2457.006047       -2434.705436       -2389.362941     -2427.024808   \n",
       "13       -2457.025230       -2434.720099       -2389.349638     -2427.031656   \n",
       "14        -897.498121        -869.524020        -845.449851      -870.823997   \n",
       "15        -907.426451        -878.058139        -854.168598      -879.884396   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0        27.724953                9  \n",
       "1        27.726240               10  \n",
       "2        14.871500                2  \n",
       "3        17.074684                1  \n",
       "4        27.898147               12  \n",
       "5        28.038683               11  \n",
       "6        14.659803                3  \n",
       "7        18.081253                4  \n",
       "8        28.149303               13  \n",
       "9        28.145028               14  \n",
       "10       21.438214                5  \n",
       "11       23.036932                7  \n",
       "12       28.144170               15  \n",
       "13       28.158250               16  \n",
       "14       21.268491                6  \n",
       "15       21.780743                8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 20, 'max_features': 1.0, 'n_estimators': 50, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbt = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = np.floor(best_gbt.predict(X_train)).astype(int)\n",
    "test_y_pred = np.floor(best_gbt.predict(X_test)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse: 20.42498764291646\n",
      "train mae: 5.685599164283327\n",
      "train r2 score: 0.8306406823557606\n"
     ]
    }
   ],
   "source": [
    "print(\"train rmse:\", root_mean_squared_error(Y_train, train_y_pred))\n",
    "print(\"train mae:\", mean_absolute_error(Y_train, train_y_pred))\n",
    "print(\"train r2 score:\", r2_score(Y_train, train_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test rmse: 29.32646273815071\n",
      "test mae: 7.677398422431186\n",
      "test r2 score: 0.6313400859656315\n"
     ]
    }
   ],
   "source": [
    "print(\"test rmse:\", root_mean_squared_error(Y_test, test_y_pred))\n",
    "print(\"test mae:\", mean_absolute_error(Y_test, test_y_pred))\n",
    "print(\"test r2 score:\", r2_score(Y_test, test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_gbt, open(os.path.join(MODELS_FOLDER, \"tuned_gbt_wo_weather.pkl\"), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
